{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b0c45e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b1bccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data into a DataFrame\n",
    "user_df = pd.read_json('data/user.json', lines=True)\n",
    "business_df = pd.read_json('data/business.json', lines=True)\n",
    "review_df = pd.read_json('data/review_train.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f44125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"yelp_train.csv\")\n",
    "val_data = pd.read_csv(\"yelp_val.csv\")\n",
    "\n",
    "# Merge user and business dataset\n",
    "train_data = pd.merge(train_data, user_df, on=\"user_id\", how=\"left\")\n",
    "train_data = pd.merge(train_data, business_df, on=\"business_id\", how=\"left\")\n",
    "val_data = pd.merge(val_data, user_df, on=\"user_id\", how=\"left\")\n",
    "val_data = pd.merge(val_data, business_df, on=\"business_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4675ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add suffix to \"user_id\" and \"business_id\"\n",
    "train_data['user_id'] = train_data ['user_id'].astype(str) + '-u'\n",
    "train_data['business_id'] = train_data['business_id'].astype(str) + '-b'\n",
    "\n",
    "val_data['user_id'] = val_data ['user_id'].astype(str) + '-u'\n",
    "val_data['business_id'] = val_data['business_id'].astype(str) + '-b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fdee2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"yelp_test_in.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bca4a8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add suffix to \"user_id\" and \"business_id\"\n",
    "test_data['user_id'] = test_data ['user_id'].astype(str) + '-u'\n",
    "test_data['business_id'] = test_data['business_id'].astype(str) + '-b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3727a",
   "metadata": {},
   "source": [
    "# Merge with PBG embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f154045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge PBG embedding with training and validation dataset\n",
    "user_embeddings_file = './embeded_features/PBG/epoch100/user_embeddings.tsv'\n",
    "business_embeddings_file = './embeded_features/PBG/epoch100/business_embeddings.tsv'\n",
    "city_embeddings_file = './embeded_features/PBG/epoch100/city_embeddings.tsv'\n",
    "category_embeddings_file = './embeded_features/PBG/epoch100/category_embeddings.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ae129f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only read the existed user_id and business_id in train and val to save memory\n",
    "unique_user_ids = set(train_data['user_id']).union(set(val_data['user_id'])).union(set(test_data['user_id']))\n",
    "unique_business_ids = set(train_data['business_id']).union(set(val_data['business_id'])).union(set(test_data['business_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a5fcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process embeddings file and filter based on IDs\n",
    "def filter_embeddings(embedding_file, ids_to_keep, id_column_name):\n",
    "    filtered_embeddings = []\n",
    "    with open(embedding_file, 'r') as file:\n",
    "        for line in file:\n",
    "            entity_id = line.split('\\t')[0]\n",
    "            if entity_id in ids_to_keep:\n",
    "                filtered_embeddings.append(line.strip().split('\\t'))\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(filtered_embeddings)\n",
    "    df.set_index(0, inplace=True)  # Set index as entity_id\n",
    "    df.columns = [f'{id_column_name}_eb{i}' for i in range(1, df.shape[1] + 1)]\n",
    "    return df\n",
    "\n",
    "# Filter the user and business embeddings\n",
    "user_embeddings = filter_embeddings(user_embeddings_file, unique_user_ids, 'user')\n",
    "business_embeddings = filter_embeddings(business_embeddings_file, unique_business_ids, 'business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b168b611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11270 entries, MWuVbyBgP4vD24Rc7UH5xw-u to hYan1ohCp1Vg58cNwPhV5g-u\n",
      "Data columns (total 100 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user_eb1    11270 non-null  object\n",
      " 1   user_eb2    11270 non-null  object\n",
      " 2   user_eb3    11270 non-null  object\n",
      " 3   user_eb4    11270 non-null  object\n",
      " 4   user_eb5    11270 non-null  object\n",
      " 5   user_eb6    11270 non-null  object\n",
      " 6   user_eb7    11270 non-null  object\n",
      " 7   user_eb8    11270 non-null  object\n",
      " 8   user_eb9    11270 non-null  object\n",
      " 9   user_eb10   11270 non-null  object\n",
      " 10  user_eb11   11270 non-null  object\n",
      " 11  user_eb12   11270 non-null  object\n",
      " 12  user_eb13   11270 non-null  object\n",
      " 13  user_eb14   11270 non-null  object\n",
      " 14  user_eb15   11270 non-null  object\n",
      " 15  user_eb16   11270 non-null  object\n",
      " 16  user_eb17   11270 non-null  object\n",
      " 17  user_eb18   11270 non-null  object\n",
      " 18  user_eb19   11270 non-null  object\n",
      " 19  user_eb20   11270 non-null  object\n",
      " 20  user_eb21   11270 non-null  object\n",
      " 21  user_eb22   11270 non-null  object\n",
      " 22  user_eb23   11270 non-null  object\n",
      " 23  user_eb24   11270 non-null  object\n",
      " 24  user_eb25   11270 non-null  object\n",
      " 25  user_eb26   11270 non-null  object\n",
      " 26  user_eb27   11270 non-null  object\n",
      " 27  user_eb28   11270 non-null  object\n",
      " 28  user_eb29   11270 non-null  object\n",
      " 29  user_eb30   11270 non-null  object\n",
      " 30  user_eb31   11270 non-null  object\n",
      " 31  user_eb32   11270 non-null  object\n",
      " 32  user_eb33   11270 non-null  object\n",
      " 33  user_eb34   11270 non-null  object\n",
      " 34  user_eb35   11270 non-null  object\n",
      " 35  user_eb36   11270 non-null  object\n",
      " 36  user_eb37   11270 non-null  object\n",
      " 37  user_eb38   11270 non-null  object\n",
      " 38  user_eb39   11270 non-null  object\n",
      " 39  user_eb40   11270 non-null  object\n",
      " 40  user_eb41   11270 non-null  object\n",
      " 41  user_eb42   11270 non-null  object\n",
      " 42  user_eb43   11270 non-null  object\n",
      " 43  user_eb44   11270 non-null  object\n",
      " 44  user_eb45   11270 non-null  object\n",
      " 45  user_eb46   11270 non-null  object\n",
      " 46  user_eb47   11270 non-null  object\n",
      " 47  user_eb48   11270 non-null  object\n",
      " 48  user_eb49   11270 non-null  object\n",
      " 49  user_eb50   11270 non-null  object\n",
      " 50  user_eb51   11270 non-null  object\n",
      " 51  user_eb52   11270 non-null  object\n",
      " 52  user_eb53   11270 non-null  object\n",
      " 53  user_eb54   11270 non-null  object\n",
      " 54  user_eb55   11270 non-null  object\n",
      " 55  user_eb56   11270 non-null  object\n",
      " 56  user_eb57   11270 non-null  object\n",
      " 57  user_eb58   11270 non-null  object\n",
      " 58  user_eb59   11270 non-null  object\n",
      " 59  user_eb60   11270 non-null  object\n",
      " 60  user_eb61   11270 non-null  object\n",
      " 61  user_eb62   11270 non-null  object\n",
      " 62  user_eb63   11270 non-null  object\n",
      " 63  user_eb64   11270 non-null  object\n",
      " 64  user_eb65   11270 non-null  object\n",
      " 65  user_eb66   11270 non-null  object\n",
      " 66  user_eb67   11270 non-null  object\n",
      " 67  user_eb68   11270 non-null  object\n",
      " 68  user_eb69   11270 non-null  object\n",
      " 69  user_eb70   11270 non-null  object\n",
      " 70  user_eb71   11270 non-null  object\n",
      " 71  user_eb72   11270 non-null  object\n",
      " 72  user_eb73   11270 non-null  object\n",
      " 73  user_eb74   11270 non-null  object\n",
      " 74  user_eb75   11270 non-null  object\n",
      " 75  user_eb76   11270 non-null  object\n",
      " 76  user_eb77   11270 non-null  object\n",
      " 77  user_eb78   11270 non-null  object\n",
      " 78  user_eb79   11270 non-null  object\n",
      " 79  user_eb80   11270 non-null  object\n",
      " 80  user_eb81   11270 non-null  object\n",
      " 81  user_eb82   11270 non-null  object\n",
      " 82  user_eb83   11270 non-null  object\n",
      " 83  user_eb84   11270 non-null  object\n",
      " 84  user_eb85   11270 non-null  object\n",
      " 85  user_eb86   11270 non-null  object\n",
      " 86  user_eb87   11270 non-null  object\n",
      " 87  user_eb88   11270 non-null  object\n",
      " 88  user_eb89   11270 non-null  object\n",
      " 89  user_eb90   11270 non-null  object\n",
      " 90  user_eb91   11270 non-null  object\n",
      " 91  user_eb92   11270 non-null  object\n",
      " 92  user_eb93   11270 non-null  object\n",
      " 93  user_eb94   11270 non-null  object\n",
      " 94  user_eb95   11270 non-null  object\n",
      " 95  user_eb96   11270 non-null  object\n",
      " 96  user_eb97   11270 non-null  object\n",
      " 97  user_eb98   11270 non-null  object\n",
      " 98  user_eb99   11270 non-null  object\n",
      " 99  user_eb100  11270 non-null  object\n",
      "dtypes: object(100)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "user_embeddings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1b2939d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25054 entries, fRu_POqPowUo6nHSRMjOPw-b to wMhovVi6ToUtVoP-YxmsOA-b\n",
      "Data columns (total 100 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   business_eb1    25054 non-null  object\n",
      " 1   business_eb2    25054 non-null  object\n",
      " 2   business_eb3    25054 non-null  object\n",
      " 3   business_eb4    25054 non-null  object\n",
      " 4   business_eb5    25054 non-null  object\n",
      " 5   business_eb6    25054 non-null  object\n",
      " 6   business_eb7    25054 non-null  object\n",
      " 7   business_eb8    25054 non-null  object\n",
      " 8   business_eb9    25054 non-null  object\n",
      " 9   business_eb10   25054 non-null  object\n",
      " 10  business_eb11   25054 non-null  object\n",
      " 11  business_eb12   25054 non-null  object\n",
      " 12  business_eb13   25054 non-null  object\n",
      " 13  business_eb14   25054 non-null  object\n",
      " 14  business_eb15   25054 non-null  object\n",
      " 15  business_eb16   25054 non-null  object\n",
      " 16  business_eb17   25054 non-null  object\n",
      " 17  business_eb18   25054 non-null  object\n",
      " 18  business_eb19   25054 non-null  object\n",
      " 19  business_eb20   25054 non-null  object\n",
      " 20  business_eb21   25054 non-null  object\n",
      " 21  business_eb22   25054 non-null  object\n",
      " 22  business_eb23   25054 non-null  object\n",
      " 23  business_eb24   25054 non-null  object\n",
      " 24  business_eb25   25054 non-null  object\n",
      " 25  business_eb26   25054 non-null  object\n",
      " 26  business_eb27   25054 non-null  object\n",
      " 27  business_eb28   25054 non-null  object\n",
      " 28  business_eb29   25054 non-null  object\n",
      " 29  business_eb30   25054 non-null  object\n",
      " 30  business_eb31   25054 non-null  object\n",
      " 31  business_eb32   25054 non-null  object\n",
      " 32  business_eb33   25054 non-null  object\n",
      " 33  business_eb34   25054 non-null  object\n",
      " 34  business_eb35   25054 non-null  object\n",
      " 35  business_eb36   25054 non-null  object\n",
      " 36  business_eb37   25054 non-null  object\n",
      " 37  business_eb38   25054 non-null  object\n",
      " 38  business_eb39   25054 non-null  object\n",
      " 39  business_eb40   25054 non-null  object\n",
      " 40  business_eb41   25054 non-null  object\n",
      " 41  business_eb42   25054 non-null  object\n",
      " 42  business_eb43   25054 non-null  object\n",
      " 43  business_eb44   25054 non-null  object\n",
      " 44  business_eb45   25054 non-null  object\n",
      " 45  business_eb46   25054 non-null  object\n",
      " 46  business_eb47   25054 non-null  object\n",
      " 47  business_eb48   25054 non-null  object\n",
      " 48  business_eb49   25054 non-null  object\n",
      " 49  business_eb50   25054 non-null  object\n",
      " 50  business_eb51   25054 non-null  object\n",
      " 51  business_eb52   25054 non-null  object\n",
      " 52  business_eb53   25054 non-null  object\n",
      " 53  business_eb54   25054 non-null  object\n",
      " 54  business_eb55   25054 non-null  object\n",
      " 55  business_eb56   25054 non-null  object\n",
      " 56  business_eb57   25054 non-null  object\n",
      " 57  business_eb58   25054 non-null  object\n",
      " 58  business_eb59   25054 non-null  object\n",
      " 59  business_eb60   25054 non-null  object\n",
      " 60  business_eb61   25054 non-null  object\n",
      " 61  business_eb62   25054 non-null  object\n",
      " 62  business_eb63   25054 non-null  object\n",
      " 63  business_eb64   25054 non-null  object\n",
      " 64  business_eb65   25054 non-null  object\n",
      " 65  business_eb66   25054 non-null  object\n",
      " 66  business_eb67   25054 non-null  object\n",
      " 67  business_eb68   25054 non-null  object\n",
      " 68  business_eb69   25054 non-null  object\n",
      " 69  business_eb70   25054 non-null  object\n",
      " 70  business_eb71   25054 non-null  object\n",
      " 71  business_eb72   25054 non-null  object\n",
      " 72  business_eb73   25054 non-null  object\n",
      " 73  business_eb74   25054 non-null  object\n",
      " 74  business_eb75   25054 non-null  object\n",
      " 75  business_eb76   25054 non-null  object\n",
      " 76  business_eb77   25054 non-null  object\n",
      " 77  business_eb78   25054 non-null  object\n",
      " 78  business_eb79   25054 non-null  object\n",
      " 79  business_eb80   25054 non-null  object\n",
      " 80  business_eb81   25054 non-null  object\n",
      " 81  business_eb82   25054 non-null  object\n",
      " 82  business_eb83   25054 non-null  object\n",
      " 83  business_eb84   25054 non-null  object\n",
      " 84  business_eb85   25054 non-null  object\n",
      " 85  business_eb86   25054 non-null  object\n",
      " 86  business_eb87   25054 non-null  object\n",
      " 87  business_eb88   25054 non-null  object\n",
      " 88  business_eb89   25054 non-null  object\n",
      " 89  business_eb90   25054 non-null  object\n",
      " 90  business_eb91   25054 non-null  object\n",
      " 91  business_eb92   25054 non-null  object\n",
      " 92  business_eb93   25054 non-null  object\n",
      " 93  business_eb94   25054 non-null  object\n",
      " 94  business_eb95   25054 non-null  object\n",
      " 95  business_eb96   25054 non-null  object\n",
      " 96  business_eb97   25054 non-null  object\n",
      " 97  business_eb98   25054 non-null  object\n",
      " 98  business_eb99   25054 non-null  object\n",
      " 99  business_eb100  25054 non-null  object\n",
      "dtypes: object(100)\n",
      "memory usage: 19.3+ MB\n"
     ]
    }
   ],
   "source": [
    "business_embeddings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ed26e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered user and business embedding file\n",
    "user_embeddings.to_csv('./embeded_features/PBG/epoch100/filtered_user_embeddings.csv')\n",
    "business_embeddings.to_csv('./embeded_features/PBG/epoch100/filtered_business_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4cf8370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read filtered user and business embedding file\n",
    "user_embeddings = pd.read_csv('./embeded_features/PBG/epoch100/filtered_user_embeddings.csv', index_col=0)\n",
    "business_embeddings = pd.read_csv('./embeded_features/PBG/epoch100/filtered_business_embeddings.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afa55cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge user and business embeddings with both training and validation datasets\n",
    "train_data = train_data.merge(user_embeddings, how='left', left_on='user_id', right_index=True)\n",
    "train_data = train_data.merge(business_embeddings, how='left', left_on='business_id', right_index=True)\n",
    "\n",
    "val_data = val_data.merge(user_embeddings, how='left', left_on='user_id', right_index=True)\n",
    "val_data = val_data.merge(business_embeddings, how='left', left_on='business_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35153d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge city embeddings with both training and validation datasets\n",
    "# Clean \"city\"\n",
    "train_data['city'] = train_data['city'].astype(str) + '-ct'\n",
    "train_data['city'] = train_data['city'].str.strip().str.lower().str.replace(' ', '_')\n",
    "val_data['city'] = val_data['city'].astype(str) + '-ct'\n",
    "val_data['city'] = val_data['city'].str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "unique_city_ids = set(train_data['city']).union(set(val_data['city']))\n",
    "city_embeddings = filter_embeddings(city_embeddings_file, unique_city_ids, 'city')\n",
    "\n",
    "train_data = train_data.merge(city_embeddings, how='left', left_on='city', right_index=True)\n",
    "val_data = val_data.merge(city_embeddings, how='left', left_on='city', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fe48bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge category embeddings with both training and validation datasets\n",
    "category_embeddings = pd.read_csv(category_embeddings_file, sep='\\t', header=None, index_col=0)\n",
    "category_embeddings.columns = [f'category_eb{i}' for i in range(1, category_embeddings.shape[1] + 1)]\n",
    "\n",
    "def average_category_embeddings(category_string, category_embeddings, embedding_size):\n",
    "    if category_string == None:\n",
    "        return [0] * embedding_size\n",
    "    cleaned_categories = [cat.replace(' ', '_') + '-c' for cat in category_string.split(\", \")]\n",
    "    embeddings = category_embeddings.loc[category_embeddings.index.intersection(cleaned_categories)]\n",
    "    if embeddings.empty:\n",
    "        return [0] * embedding_size\n",
    "    return embeddings.mean().tolist()\n",
    "\n",
    "# The number of dimensions in your embeddings is 100\n",
    "embedding_size = 100\n",
    "category_embedding_cols = [f'category_eb{i}' for i in range(1, embedding_size + 1)]\n",
    "\n",
    "train_avg_category_embeddings = train_data['categories'].apply(lambda x: average_category_embeddings(x, category_embeddings, embedding_size))\n",
    "val_avg_category_embeddings = val_data['categories'].apply(lambda x: average_category_embeddings(x, category_embeddings, embedding_size))\n",
    "\n",
    "# Convert lists of embeddings to a DataFrame\n",
    "train_avg_category_embeddings_df = pd.DataFrame(train_avg_category_embeddings.tolist(), index=train_data.index, columns=category_embedding_cols)\n",
    "val_avg_category_embeddings_df = pd.DataFrame(val_avg_category_embeddings.tolist(), index=val_data.index, columns=category_embedding_cols)\n",
    "\n",
    "# Concatenate the new DataFrame with the original training and validation data\n",
    "train_data = pd.concat([train_data, train_avg_category_embeddings_df], axis=1)\n",
    "val_data = pd.concat([val_data, val_avg_category_embeddings_df], axis=1)\n",
    "\n",
    "# Drop the original 'categories' column if no longer needed\n",
    "train_data.drop('categories', axis=1, inplace=True)\n",
    "val_data.drop('categories', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f09ea6a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>name_x</th>\n",
       "      <th>review_count_x</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>friends</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>...</th>\n",
       "      <th>category_eb91</th>\n",
       "      <th>category_eb92</th>\n",
       "      <th>category_eb93</th>\n",
       "      <th>category_eb94</th>\n",
       "      <th>category_eb95</th>\n",
       "      <th>category_eb96</th>\n",
       "      <th>category_eb97</th>\n",
       "      <th>category_eb98</th>\n",
       "      <th>category_eb99</th>\n",
       "      <th>category_eb100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vxR_YV0atFxIxfOnF9uHjQ-u</td>\n",
       "      <td>gTw6PENNGl68ZPUpYWP50A-b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Debbie</td>\n",
       "      <td>353</td>\n",
       "      <td>2006-06-16</td>\n",
       "      <td>ir2V_EKfO7XOfKkmX6khCg, uukJrcxFaQFYlbXDql4Kbw...</td>\n",
       "      <td>2005</td>\n",
       "      <td>1826</td>\n",
       "      <td>1872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061217</td>\n",
       "      <td>-0.048337</td>\n",
       "      <td>-0.167386</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.097196</td>\n",
       "      <td>0.160434</td>\n",
       "      <td>-0.051821</td>\n",
       "      <td>-0.223712</td>\n",
       "      <td>0.018650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o0p-iTC5yTBV5Yab_7es4g-u</td>\n",
       "      <td>iAuOpYDfOTuzQ6OPpEiGwA-b</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Scott</td>\n",
       "      <td>433</td>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>CkyNJfLv6yx55Pdjq_8T_g, 55sr442Csr6cJ3c430MSow...</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>-0.092869</td>\n",
       "      <td>-0.029402</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>-0.074395</td>\n",
       "      <td>0.241833</td>\n",
       "      <td>-0.016240</td>\n",
       "      <td>-0.104173</td>\n",
       "      <td>-0.093384</td>\n",
       "      <td>-0.008089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-qj9ouN0bzMXz1vfEslG-A-u</td>\n",
       "      <td>5j7BnXXvlS69uLVHrY9Upw-b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jaddahti</td>\n",
       "      <td>154</td>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>-xDW3gYiYaoeVASXywTPgw, OueXAik2P-eUcXbd1qGXKw...</td>\n",
       "      <td>2660</td>\n",
       "      <td>644</td>\n",
       "      <td>1003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174777</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>-0.064023</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>-0.094246</td>\n",
       "      <td>0.322639</td>\n",
       "      <td>-0.236703</td>\n",
       "      <td>0.235710</td>\n",
       "      <td>0.063903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E43QxgV87Ij6KxMCHcijKw-u</td>\n",
       "      <td>jUYp798M93Mpcjys_TTgsQ-b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Nikki</td>\n",
       "      <td>668</td>\n",
       "      <td>2012-03-26</td>\n",
       "      <td>pufGgg3EuY_As7cu__pM1w, 3ONXl3eodyqkhysi-UoseA...</td>\n",
       "      <td>1214</td>\n",
       "      <td>180</td>\n",
       "      <td>826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159266</td>\n",
       "      <td>-0.072648</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.261897</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.113596</td>\n",
       "      <td>-0.087337</td>\n",
       "      <td>-0.187862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T13IBpJITI32a1k41rc-tg-u</td>\n",
       "      <td>3MntE_HWbNNoyiLGxywjYA-b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Aimee</td>\n",
       "      <td>304</td>\n",
       "      <td>2015-12-18</td>\n",
       "      <td>swUxTfJ96XZJ0ufmljJiXQ, T1oHdzsrFeTrQhHfNdls8A...</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049052</td>\n",
       "      <td>-0.044036</td>\n",
       "      <td>-0.050409</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.155675</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>-0.228835</td>\n",
       "      <td>-0.034429</td>\n",
       "      <td>0.291386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455849</th>\n",
       "      <td>Tsm8VraTp5OGyVALtUiCeQ-u</td>\n",
       "      <td>DXlDzOcpdUE_F21tok0fgw-b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Monica</td>\n",
       "      <td>951</td>\n",
       "      <td>2009-10-25</td>\n",
       "      <td>VAI4LygxcbgHctXSS63kbg, 9uwTqhvD5340tgbD6BJrGA...</td>\n",
       "      <td>16440</td>\n",
       "      <td>7770</td>\n",
       "      <td>15239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131627</td>\n",
       "      <td>-0.035727</td>\n",
       "      <td>0.097267</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>-0.098105</td>\n",
       "      <td>0.290240</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>-0.108009</td>\n",
       "      <td>-0.011020</td>\n",
       "      <td>-0.090139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455850</th>\n",
       "      <td>BrqGnby6aahIOc0N_1x0Bg-u</td>\n",
       "      <td>_UEQPDDiSgyYqjORWeLfJg-b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Joah</td>\n",
       "      <td>63</td>\n",
       "      <td>2012-07-13</td>\n",
       "      <td>uOIaBdtM_uNHDNWW51fTgg, bu978PmR7CL4TfSCqE28RQ...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068299</td>\n",
       "      <td>-0.076515</td>\n",
       "      <td>-0.224999</td>\n",
       "      <td>0.349166</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.032217</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>-0.016249</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.007497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455851</th>\n",
       "      <td>-lh59ko3dxChBSZ9U7LfUw-u</td>\n",
       "      <td>KPV_FVNWkgmYh1ArVlt6kg-b</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lissa</td>\n",
       "      <td>902</td>\n",
       "      <td>2007-08-14</td>\n",
       "      <td>wXVrWYbX5pldpqsxcVk_6g, OK7jABaab-ITXjFopirh2A...</td>\n",
       "      <td>462</td>\n",
       "      <td>152</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009964</td>\n",
       "      <td>-0.037476</td>\n",
       "      <td>-0.019379</td>\n",
       "      <td>-0.169863</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.450110</td>\n",
       "      <td>0.181399</td>\n",
       "      <td>0.063993</td>\n",
       "      <td>-0.198551</td>\n",
       "      <td>-0.088449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455852</th>\n",
       "      <td>3VPVQ4fCNF1vYayTJUxKNA-u</td>\n",
       "      <td>YNDxeeRUARbd8GRnscJSvg-b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sonya</td>\n",
       "      <td>52</td>\n",
       "      <td>2010-07-27</td>\n",
       "      <td>bHwcGZP51S02OY72OZi7wg, kmSOityfRkz73gfeBJdXqw...</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102350</td>\n",
       "      <td>-0.106567</td>\n",
       "      <td>-0.072236</td>\n",
       "      <td>0.151984</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.148726</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-0.093215</td>\n",
       "      <td>0.116072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455853</th>\n",
       "      <td>pkq41Qh9yGOI_4pwdVmmDg-u</td>\n",
       "      <td>4ugJ4F8jDJ9-2dEiZ47wLg-b</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>200</td>\n",
       "      <td>2011-04-20</td>\n",
       "      <td>G8L4MrjDF7FFVqCm8OZwIw, xGRAqxoTEn8Kug5nhU_orA...</td>\n",
       "      <td>70</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209568</td>\n",
       "      <td>0.065104</td>\n",
       "      <td>-0.428710</td>\n",
       "      <td>0.077216</td>\n",
       "      <td>0.062782</td>\n",
       "      <td>-0.017567</td>\n",
       "      <td>0.393408</td>\n",
       "      <td>-0.082681</td>\n",
       "      <td>-0.204207</td>\n",
       "      <td>0.199612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455854 rows Ã— 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         user_id               business_id  stars_x    name_x  \\\n",
       "0       vxR_YV0atFxIxfOnF9uHjQ-u  gTw6PENNGl68ZPUpYWP50A-b      5.0    Debbie   \n",
       "1       o0p-iTC5yTBV5Yab_7es4g-u  iAuOpYDfOTuzQ6OPpEiGwA-b      4.0     Scott   \n",
       "2       -qj9ouN0bzMXz1vfEslG-A-u  5j7BnXXvlS69uLVHrY9Upw-b      2.0  Jaddahti   \n",
       "3       E43QxgV87Ij6KxMCHcijKw-u  jUYp798M93Mpcjys_TTgsQ-b      5.0     Nikki   \n",
       "4       T13IBpJITI32a1k41rc-tg-u  3MntE_HWbNNoyiLGxywjYA-b      5.0     Aimee   \n",
       "...                          ...                       ...      ...       ...   \n",
       "455849  Tsm8VraTp5OGyVALtUiCeQ-u  DXlDzOcpdUE_F21tok0fgw-b      5.0    Monica   \n",
       "455850  BrqGnby6aahIOc0N_1x0Bg-u  _UEQPDDiSgyYqjORWeLfJg-b      1.0      Joah   \n",
       "455851  -lh59ko3dxChBSZ9U7LfUw-u  KPV_FVNWkgmYh1ArVlt6kg-b      3.0     Lissa   \n",
       "455852  3VPVQ4fCNF1vYayTJUxKNA-u  YNDxeeRUARbd8GRnscJSvg-b      5.0     Sonya   \n",
       "455853  pkq41Qh9yGOI_4pwdVmmDg-u  4ugJ4F8jDJ9-2dEiZ47wLg-b      4.0     Cathy   \n",
       "\n",
       "        review_count_x yelping_since  \\\n",
       "0                  353    2006-06-16   \n",
       "1                  433    2010-01-08   \n",
       "2                  154    2012-06-30   \n",
       "3                  668    2012-03-26   \n",
       "4                  304    2015-12-18   \n",
       "...                ...           ...   \n",
       "455849             951    2009-10-25   \n",
       "455850              63    2012-07-13   \n",
       "455851             902    2007-08-14   \n",
       "455852              52    2010-07-27   \n",
       "455853             200    2011-04-20   \n",
       "\n",
       "                                                  friends  useful  funny  \\\n",
       "0       ir2V_EKfO7XOfKkmX6khCg, uukJrcxFaQFYlbXDql4Kbw...    2005   1826   \n",
       "1       CkyNJfLv6yx55Pdjq_8T_g, 55sr442Csr6cJ3c430MSow...      22     19   \n",
       "2       -xDW3gYiYaoeVASXywTPgw, OueXAik2P-eUcXbd1qGXKw...    2660    644   \n",
       "3       pufGgg3EuY_As7cu__pM1w, 3ONXl3eodyqkhysi-UoseA...    1214    180   \n",
       "4       swUxTfJ96XZJ0ufmljJiXQ, T1oHdzsrFeTrQhHfNdls8A...      14      9   \n",
       "...                                                   ...     ...    ...   \n",
       "455849  VAI4LygxcbgHctXSS63kbg, 9uwTqhvD5340tgbD6BJrGA...   16440   7770   \n",
       "455850  uOIaBdtM_uNHDNWW51fTgg, bu978PmR7CL4TfSCqE28RQ...       8      3   \n",
       "455851  wXVrWYbX5pldpqsxcVk_6g, OK7jABaab-ITXjFopirh2A...     462    152   \n",
       "455852  bHwcGZP51S02OY72OZi7wg, kmSOityfRkz73gfeBJdXqw...      27     10   \n",
       "455853  G8L4MrjDF7FFVqCm8OZwIw, xGRAqxoTEn8Kug5nhU_orA...      70     39   \n",
       "\n",
       "         cool  ...  category_eb91 category_eb92  category_eb93  category_eb94  \\\n",
       "0        1872  ...       0.061217     -0.048337      -0.167386       0.130525   \n",
       "1          33  ...       0.046681     -0.092869      -0.029402       0.012135   \n",
       "2        1003  ...      -0.174777      0.044597      -0.064023       0.115727   \n",
       "3         826  ...      -0.159266     -0.072648       0.023384       0.261897   \n",
       "4           8  ...       0.049052     -0.044036      -0.050409       0.138590   \n",
       "...       ...  ...            ...           ...            ...            ...   \n",
       "455849  15239  ...       0.131627     -0.035727       0.097267       0.017720   \n",
       "455850      0  ...       0.068299     -0.076515      -0.224999       0.349166   \n",
       "455851    345  ...       0.009964     -0.037476      -0.019379      -0.169863   \n",
       "455852     23  ...       0.102350     -0.106567      -0.072236       0.151984   \n",
       "455853     43  ...       0.209568      0.065104      -0.428710       0.077216   \n",
       "\n",
       "        category_eb95  category_eb96  category_eb97  category_eb98  \\\n",
       "0            0.037815       0.097196       0.160434      -0.051821   \n",
       "1           -0.074395       0.241833      -0.016240      -0.104173   \n",
       "2            0.029150      -0.094246       0.322639      -0.236703   \n",
       "3           -0.019492       0.004084       0.063447       0.113596   \n",
       "4            0.155675       0.059859       0.365941      -0.228835   \n",
       "...               ...            ...            ...            ...   \n",
       "455849      -0.098105       0.290240      -0.123005      -0.108009   \n",
       "455850       0.026720       0.032217       0.034222      -0.016249   \n",
       "455851       0.051777       0.450110       0.181399       0.063993   \n",
       "455852       0.023981       0.143254       0.148726      -0.021718   \n",
       "455853       0.062782      -0.017567       0.393408      -0.082681   \n",
       "\n",
       "        category_eb99  category_eb100  \n",
       "0           -0.223712        0.018650  \n",
       "1           -0.093384       -0.008089  \n",
       "2            0.235710        0.063903  \n",
       "3           -0.087337       -0.187862  \n",
       "4           -0.034429        0.291386  \n",
       "...               ...             ...  \n",
       "455849      -0.011020       -0.090139  \n",
       "455850       0.011128        0.007497  \n",
       "455851      -0.198551       -0.088449  \n",
       "455852      -0.093215        0.116072  \n",
       "455853      -0.204207        0.199612  \n",
       "\n",
       "[455854 rows x 437 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b01f2c",
   "metadata": {},
   "source": [
    "# Other feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3901983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 455854 entries, 0 to 455853\n",
      "Columns: 426 entries, stars_x to num_of_elites\n",
      "dtypes: float64(305), int64(21), object(100)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "# Delete uncessary features\n",
    "columns_to_drop = [\n",
    "    'user_id', 'business_id',   # Identifiers\n",
    "    'name_x', 'name_y',        # User and business names (assuming name_x is from the user dataset and name_y is from the business dataset)\n",
    "    'address', 'postal_code',  # Specific location details which might not be generalizable\n",
    "    'hours',                   # Detailed operational hours (unless you plan to engineer features from it)\n",
    "    'neighborhood',            # Can be dropped if you're using city and state for location info\n",
    "    'attributes',              # Might be complex to parse, but can be useful if processed correctly      \n",
    "    'city', 'state'            # Use Latitude and Longitude\n",
    "]\n",
    "\n",
    "train_data = train_data.drop(columns=columns_to_drop)\n",
    "val_data = val_data.drop(columns=columns_to_drop)\n",
    "\n",
    "def feature_process_noreview(train_data):\n",
    "    # Convert \"yelping_since\" to \"yelping_duration\":\n",
    "    collection_date = pd.to_datetime(\"2018-07-02\") # latest review date\n",
    "    train_data['yelping_since'] = pd.to_datetime(train_data['yelping_since'])\n",
    "    train_data['yelping_duration'] = (collection_date - train_data['yelping_since']).dt.days\n",
    "\n",
    "    # Convert \"friends\" to \"num_of_friends\":\n",
    "    train_data['num_of_friends'] = train_data['friends'].apply(lambda x: 0 if x == \"None\" else len(x.split(',')))\n",
    "\n",
    "    # Convert \"elite\" to \"num_of_elites\":\n",
    "    train_data['num_of_elites'] = train_data['elite'].apply(lambda x: 0 if x == \"None\" else len(x.split(',')))\n",
    "\n",
    "    train_data.drop(['yelping_since', 'friends', 'elite'], axis=1, inplace=True)\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "train_data = feature_process_noreview(train_data)\n",
    "val_data = feature_process_noreview(val_data)\n",
    "\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61aede3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_x</th>\n",
       "      <th>review_count_x</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>fans</th>\n",
       "      <th>average_stars</th>\n",
       "      <th>compliment_hot</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>...</th>\n",
       "      <th>category_eb94</th>\n",
       "      <th>category_eb95</th>\n",
       "      <th>category_eb96</th>\n",
       "      <th>category_eb97</th>\n",
       "      <th>category_eb98</th>\n",
       "      <th>category_eb99</th>\n",
       "      <th>category_eb100</th>\n",
       "      <th>yelping_duration</th>\n",
       "      <th>num_of_friends</th>\n",
       "      <th>num_of_elites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>353</td>\n",
       "      <td>2005</td>\n",
       "      <td>1826</td>\n",
       "      <td>1872</td>\n",
       "      <td>69</td>\n",
       "      <td>4.11</td>\n",
       "      <td>213</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130525</td>\n",
       "      <td>0.037815</td>\n",
       "      <td>0.097196</td>\n",
       "      <td>0.160434</td>\n",
       "      <td>-0.051821</td>\n",
       "      <td>-0.223712</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>4399</td>\n",
       "      <td>787</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>433</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>3.92</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012135</td>\n",
       "      <td>-0.074395</td>\n",
       "      <td>0.241833</td>\n",
       "      <td>-0.016240</td>\n",
       "      <td>-0.104173</td>\n",
       "      <td>-0.093384</td>\n",
       "      <td>-0.008089</td>\n",
       "      <td>3097</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>154</td>\n",
       "      <td>2660</td>\n",
       "      <td>644</td>\n",
       "      <td>1003</td>\n",
       "      <td>9</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115727</td>\n",
       "      <td>0.029150</td>\n",
       "      <td>-0.094246</td>\n",
       "      <td>0.322639</td>\n",
       "      <td>-0.236703</td>\n",
       "      <td>0.235710</td>\n",
       "      <td>0.063903</td>\n",
       "      <td>2193</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>668</td>\n",
       "      <td>1214</td>\n",
       "      <td>180</td>\n",
       "      <td>826</td>\n",
       "      <td>407</td>\n",
       "      <td>4.11</td>\n",
       "      <td>143</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261897</td>\n",
       "      <td>-0.019492</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.113596</td>\n",
       "      <td>-0.087337</td>\n",
       "      <td>-0.187862</td>\n",
       "      <td>2289</td>\n",
       "      <td>2598</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>304</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3.60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138590</td>\n",
       "      <td>0.155675</td>\n",
       "      <td>0.059859</td>\n",
       "      <td>0.365941</td>\n",
       "      <td>-0.228835</td>\n",
       "      <td>-0.034429</td>\n",
       "      <td>0.291386</td>\n",
       "      <td>927</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455849</th>\n",
       "      <td>5.0</td>\n",
       "      <td>951</td>\n",
       "      <td>16440</td>\n",
       "      <td>7770</td>\n",
       "      <td>15239</td>\n",
       "      <td>81</td>\n",
       "      <td>3.47</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>-0.098105</td>\n",
       "      <td>0.290240</td>\n",
       "      <td>-0.123005</td>\n",
       "      <td>-0.108009</td>\n",
       "      <td>-0.011020</td>\n",
       "      <td>-0.090139</td>\n",
       "      <td>3172</td>\n",
       "      <td>174</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455850</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349166</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.032217</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>-0.016249</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>2180</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455851</th>\n",
       "      <td>3.0</td>\n",
       "      <td>902</td>\n",
       "      <td>462</td>\n",
       "      <td>152</td>\n",
       "      <td>345</td>\n",
       "      <td>127</td>\n",
       "      <td>3.71</td>\n",
       "      <td>420</td>\n",
       "      <td>35</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169863</td>\n",
       "      <td>0.051777</td>\n",
       "      <td>0.450110</td>\n",
       "      <td>0.181399</td>\n",
       "      <td>0.063993</td>\n",
       "      <td>-0.198551</td>\n",
       "      <td>-0.088449</td>\n",
       "      <td>3975</td>\n",
       "      <td>1221</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455852</th>\n",
       "      <td>5.0</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151984</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.148726</td>\n",
       "      <td>-0.021718</td>\n",
       "      <td>-0.093215</td>\n",
       "      <td>0.116072</td>\n",
       "      <td>2897</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455853</th>\n",
       "      <td>4.0</td>\n",
       "      <td>200</td>\n",
       "      <td>70</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>3.94</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077216</td>\n",
       "      <td>0.062782</td>\n",
       "      <td>-0.017567</td>\n",
       "      <td>0.393408</td>\n",
       "      <td>-0.082681</td>\n",
       "      <td>-0.204207</td>\n",
       "      <td>0.199612</td>\n",
       "      <td>2630</td>\n",
       "      <td>533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455854 rows Ã— 426 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars_x  review_count_x  useful  funny   cool  fans  average_stars  \\\n",
       "0           5.0             353    2005   1826   1872    69           4.11   \n",
       "1           4.0             433      22     19     33    12           3.92   \n",
       "2           2.0             154    2660    644   1003     9           3.69   \n",
       "3           5.0             668    1214    180    826   407           4.11   \n",
       "4           5.0             304      14      9      8    11           3.60   \n",
       "...         ...             ...     ...    ...    ...   ...            ...   \n",
       "455849      5.0             951   16440   7770  15239    81           3.47   \n",
       "455850      1.0              63       8      3      0     5           3.63   \n",
       "455851      3.0             902     462    152    345   127           3.71   \n",
       "455852      5.0              52      27     10     23     1           3.33   \n",
       "455853      4.0             200      70     39     43    19           3.94   \n",
       "\n",
       "        compliment_hot  compliment_more  compliment_profile  ...  \\\n",
       "0                  213               15                   6  ...   \n",
       "1                    7                4                   2  ...   \n",
       "2                   12                6                   0  ...   \n",
       "3                  143               18                   8  ...   \n",
       "4                    5                2                   0  ...   \n",
       "...                ...              ...                 ...  ...   \n",
       "455849              55               10                   8  ...   \n",
       "455850               0                0                   1  ...   \n",
       "455851             420               35                  57  ...   \n",
       "455852               0                1                   0  ...   \n",
       "455853              30                4                   3  ...   \n",
       "\n",
       "        category_eb94  category_eb95  category_eb96  category_eb97  \\\n",
       "0            0.130525       0.037815       0.097196       0.160434   \n",
       "1            0.012135      -0.074395       0.241833      -0.016240   \n",
       "2            0.115727       0.029150      -0.094246       0.322639   \n",
       "3            0.261897      -0.019492       0.004084       0.063447   \n",
       "4            0.138590       0.155675       0.059859       0.365941   \n",
       "...               ...            ...            ...            ...   \n",
       "455849       0.017720      -0.098105       0.290240      -0.123005   \n",
       "455850       0.349166       0.026720       0.032217       0.034222   \n",
       "455851      -0.169863       0.051777       0.450110       0.181399   \n",
       "455852       0.151984       0.023981       0.143254       0.148726   \n",
       "455853       0.077216       0.062782      -0.017567       0.393408   \n",
       "\n",
       "        category_eb98  category_eb99  category_eb100  yelping_duration  \\\n",
       "0           -0.051821      -0.223712        0.018650              4399   \n",
       "1           -0.104173      -0.093384       -0.008089              3097   \n",
       "2           -0.236703       0.235710        0.063903              2193   \n",
       "3            0.113596      -0.087337       -0.187862              2289   \n",
       "4           -0.228835      -0.034429        0.291386               927   \n",
       "...               ...            ...             ...               ...   \n",
       "455849      -0.108009      -0.011020       -0.090139              3172   \n",
       "455850      -0.016249       0.011128        0.007497              2180   \n",
       "455851       0.063993      -0.198551       -0.088449              3975   \n",
       "455852      -0.021718      -0.093215        0.116072              2897   \n",
       "455853      -0.082681      -0.204207        0.199612              2630   \n",
       "\n",
       "        num_of_friends  num_of_elites  \n",
       "0                  787              8  \n",
       "1                  109              4  \n",
       "2                   55              0  \n",
       "3                 2598              6  \n",
       "4                   98              3  \n",
       "...                ...            ...  \n",
       "455849             174              8  \n",
       "455850              99              0  \n",
       "455851            1221             10  \n",
       "455852             151              0  \n",
       "455853             533              2  \n",
       "\n",
       "[455854 rows x 426 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c784041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert embedding values for float for training\n",
    "\n",
    "# List of embedding column names\n",
    "# embedding_columns = [col for col in train_data.columns if 'eb' in col]\n",
    "\n",
    "# Convert each embedding column to numeric type (float)\n",
    "# for col in embedding_columns:\n",
    "#    train_data[col] = pd.to_numeric(train_data[col], errors='raise')\n",
    "#    val_data[col] = pd.to_numeric(val_data[col], errors='raise')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "15d8adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all embedding columns to float at once\n",
    "embedding_columns = [col for col in train_data.columns if 'eb' in col]\n",
    "train_data[embedding_columns] = train_data[embedding_columns].astype(float)\n",
    "val_data[embedding_columns] = val_data[embedding_columns].astype(float).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8aaf60",
   "metadata": {},
   "source": [
    "# Training XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d12a8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('stars_x', axis=1) # Features\n",
    "y_train = train_data['stars_x'] # Target variable\n",
    "\n",
    "X_val = val_data.drop('stars_x', axis=1) # Features for evaluation data\n",
    "y_val = val_data['stars_x'] # True ratings for evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43b548b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.40723\tvalid-rmse:3.40508\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:3.09186\tvalid-rmse:3.08961\n",
      "[20]\ttrain-rmse:2.81173\tvalid-rmse:2.80941\n",
      "[30]\ttrain-rmse:2.56421\tvalid-rmse:2.56179\n",
      "[40]\ttrain-rmse:2.34481\tvalid-rmse:2.34237\n",
      "[50]\ttrain-rmse:2.15171\tvalid-rmse:2.14925\n",
      "[60]\ttrain-rmse:1.98215\tvalid-rmse:1.9797\n",
      "[70]\ttrain-rmse:1.83348\tvalid-rmse:1.83108\n",
      "[80]\ttrain-rmse:1.70424\tvalid-rmse:1.70196\n",
      "[90]\ttrain-rmse:1.59128\tvalid-rmse:1.58924\n",
      "[100]\ttrain-rmse:1.49389\tvalid-rmse:1.49217\n",
      "[110]\ttrain-rmse:1.41042\tvalid-rmse:1.40912\n",
      "[120]\ttrain-rmse:1.33875\tvalid-rmse:1.33804\n",
      "[130]\ttrain-rmse:1.27791\tvalid-rmse:1.2779\n",
      "[140]\ttrain-rmse:1.22603\tvalid-rmse:1.22683\n",
      "[150]\ttrain-rmse:1.18207\tvalid-rmse:1.18382\n",
      "[160]\ttrain-rmse:1.1451\tvalid-rmse:1.14789\n",
      "[170]\ttrain-rmse:1.11406\tvalid-rmse:1.11797\n",
      "[180]\ttrain-rmse:1.08796\tvalid-rmse:1.09304\n",
      "[190]\ttrain-rmse:1.06627\tvalid-rmse:1.07248\n",
      "[200]\ttrain-rmse:1.04782\tvalid-rmse:1.05533\n",
      "[210]\ttrain-rmse:1.0324\tvalid-rmse:1.04119\n",
      "[220]\ttrain-rmse:1.01962\tvalid-rmse:1.02962\n",
      "[230]\ttrain-rmse:1.00879\tvalid-rmse:1.02006\n",
      "[240]\ttrain-rmse:0.999636\tvalid-rmse:1.01215\n",
      "[250]\ttrain-rmse:0.991984\tvalid-rmse:1.0057\n",
      "[260]\ttrain-rmse:0.985471\tvalid-rmse:1.00038\n",
      "[270]\ttrain-rmse:0.979873\tvalid-rmse:0.995959\n",
      "[280]\ttrain-rmse:0.975052\tvalid-rmse:0.992296\n",
      "[290]\ttrain-rmse:0.971006\tvalid-rmse:0.989322\n",
      "[300]\ttrain-rmse:0.967399\tvalid-rmse:0.98687\n",
      "[310]\ttrain-rmse:0.964244\tvalid-rmse:0.984819\n",
      "[320]\ttrain-rmse:0.961459\tvalid-rmse:0.983103\n",
      "[330]\ttrain-rmse:0.958996\tvalid-rmse:0.981695\n",
      "[340]\ttrain-rmse:0.956892\tvalid-rmse:0.980504\n",
      "[350]\ttrain-rmse:0.954887\tvalid-rmse:0.979503\n",
      "[360]\ttrain-rmse:0.953018\tvalid-rmse:0.97868\n",
      "[370]\ttrain-rmse:0.951339\tvalid-rmse:0.977986\n",
      "[380]\ttrain-rmse:0.949808\tvalid-rmse:0.977386\n",
      "[390]\ttrain-rmse:0.948378\tvalid-rmse:0.976864\n",
      "[400]\ttrain-rmse:0.947031\tvalid-rmse:0.976438\n",
      "[410]\ttrain-rmse:0.945757\tvalid-rmse:0.976082\n",
      "[420]\ttrain-rmse:0.944535\tvalid-rmse:0.975753\n",
      "[430]\ttrain-rmse:0.943432\tvalid-rmse:0.975467\n",
      "[440]\ttrain-rmse:0.94243\tvalid-rmse:0.975235\n",
      "[450]\ttrain-rmse:0.941327\tvalid-rmse:0.975003\n",
      "[460]\ttrain-rmse:0.940324\tvalid-rmse:0.974788\n",
      "[470]\ttrain-rmse:0.939324\tvalid-rmse:0.974595\n",
      "[480]\ttrain-rmse:0.938332\tvalid-rmse:0.974421\n",
      "[490]\ttrain-rmse:0.937442\tvalid-rmse:0.974281\n",
      "[500]\ttrain-rmse:0.936604\tvalid-rmse:0.974143\n",
      "[510]\ttrain-rmse:0.935769\tvalid-rmse:0.974019\n",
      "[520]\ttrain-rmse:0.934988\tvalid-rmse:0.973914\n",
      "[530]\ttrain-rmse:0.934155\tvalid-rmse:0.973805\n",
      "[540]\ttrain-rmse:0.933338\tvalid-rmse:0.97371\n",
      "[550]\ttrain-rmse:0.932589\tvalid-rmse:0.973624\n",
      "[560]\ttrain-rmse:0.931934\tvalid-rmse:0.973543\n",
      "[570]\ttrain-rmse:0.93116\tvalid-rmse:0.973458\n",
      "[580]\ttrain-rmse:0.930453\tvalid-rmse:0.973389\n",
      "[590]\ttrain-rmse:0.929878\tvalid-rmse:0.973328\n",
      "[600]\ttrain-rmse:0.929311\tvalid-rmse:0.973268\n",
      "[610]\ttrain-rmse:0.928687\tvalid-rmse:0.973202\n",
      "[620]\ttrain-rmse:0.928018\tvalid-rmse:0.973131\n",
      "[630]\ttrain-rmse:0.927322\tvalid-rmse:0.973068\n",
      "[640]\ttrain-rmse:0.926712\tvalid-rmse:0.973011\n",
      "[650]\ttrain-rmse:0.926091\tvalid-rmse:0.972944\n",
      "[660]\ttrain-rmse:0.925466\tvalid-rmse:0.972892\n",
      "[670]\ttrain-rmse:0.924844\tvalid-rmse:0.972843\n",
      "[680]\ttrain-rmse:0.924262\tvalid-rmse:0.972789\n",
      "[690]\ttrain-rmse:0.9236\tvalid-rmse:0.972748\n",
      "[700]\ttrain-rmse:0.923119\tvalid-rmse:0.972696\n",
      "[710]\ttrain-rmse:0.922597\tvalid-rmse:0.972638\n",
      "[720]\ttrain-rmse:0.922098\tvalid-rmse:0.972597\n",
      "[730]\ttrain-rmse:0.92144\tvalid-rmse:0.972557\n",
      "[740]\ttrain-rmse:0.920861\tvalid-rmse:0.972511\n",
      "[750]\ttrain-rmse:0.92039\tvalid-rmse:0.972477\n",
      "[760]\ttrain-rmse:0.919836\tvalid-rmse:0.972447\n",
      "[770]\ttrain-rmse:0.919301\tvalid-rmse:0.972407\n",
      "[780]\ttrain-rmse:0.918815\tvalid-rmse:0.972376\n",
      "[790]\ttrain-rmse:0.918251\tvalid-rmse:0.972348\n",
      "[800]\ttrain-rmse:0.917723\tvalid-rmse:0.972309\n",
      "[810]\ttrain-rmse:0.917181\tvalid-rmse:0.972296\n",
      "[820]\ttrain-rmse:0.916598\tvalid-rmse:0.97226\n",
      "[830]\ttrain-rmse:0.915964\tvalid-rmse:0.972227\n",
      "[840]\ttrain-rmse:0.915579\tvalid-rmse:0.972214\n",
      "[850]\ttrain-rmse:0.915083\tvalid-rmse:0.972188\n",
      "[860]\ttrain-rmse:0.914675\tvalid-rmse:0.972161\n",
      "[870]\ttrain-rmse:0.914191\tvalid-rmse:0.972141\n",
      "[880]\ttrain-rmse:0.913669\tvalid-rmse:0.972111\n",
      "[890]\ttrain-rmse:0.913131\tvalid-rmse:0.972082\n",
      "[900]\ttrain-rmse:0.912674\tvalid-rmse:0.972041\n",
      "[910]\ttrain-rmse:0.912259\tvalid-rmse:0.972022\n",
      "[920]\ttrain-rmse:0.911815\tvalid-rmse:0.972011\n",
      "[930]\ttrain-rmse:0.911368\tvalid-rmse:0.971991\n",
      "[940]\ttrain-rmse:0.910884\tvalid-rmse:0.971962\n",
      "[950]\ttrain-rmse:0.910399\tvalid-rmse:0.971946\n",
      "[960]\ttrain-rmse:0.910019\tvalid-rmse:0.971924\n",
      "[970]\ttrain-rmse:0.909552\tvalid-rmse:0.971903\n",
      "[980]\ttrain-rmse:0.909043\tvalid-rmse:0.971871\n",
      "[990]\ttrain-rmse:0.908503\tvalid-rmse:0.971842\n",
      "[1000]\ttrain-rmse:0.908051\tvalid-rmse:0.971828\n",
      "[1010]\ttrain-rmse:0.90759\tvalid-rmse:0.9718\n",
      "[1020]\ttrain-rmse:0.907176\tvalid-rmse:0.971783\n",
      "[1030]\ttrain-rmse:0.906726\tvalid-rmse:0.971758\n",
      "[1040]\ttrain-rmse:0.906309\tvalid-rmse:0.971738\n",
      "[1050]\ttrain-rmse:0.90595\tvalid-rmse:0.971734\n",
      "[1060]\ttrain-rmse:0.905621\tvalid-rmse:0.971711\n",
      "[1070]\ttrain-rmse:0.905181\tvalid-rmse:0.971701\n",
      "[1080]\ttrain-rmse:0.904842\tvalid-rmse:0.971679\n",
      "[1090]\ttrain-rmse:0.904399\tvalid-rmse:0.971659\n",
      "[1100]\ttrain-rmse:0.903981\tvalid-rmse:0.971653\n",
      "[1110]\ttrain-rmse:0.903568\tvalid-rmse:0.97163\n",
      "[1120]\ttrain-rmse:0.90311\tvalid-rmse:0.971621\n",
      "[1130]\ttrain-rmse:0.902651\tvalid-rmse:0.971617\n",
      "[1140]\ttrain-rmse:0.902247\tvalid-rmse:0.971595\n",
      "[1150]\ttrain-rmse:0.901845\tvalid-rmse:0.971574\n",
      "[1160]\ttrain-rmse:0.901403\tvalid-rmse:0.971565\n",
      "[1170]\ttrain-rmse:0.900951\tvalid-rmse:0.971555\n",
      "[1180]\ttrain-rmse:0.900506\tvalid-rmse:0.971543\n",
      "[1190]\ttrain-rmse:0.900048\tvalid-rmse:0.971525\n",
      "[1200]\ttrain-rmse:0.899638\tvalid-rmse:0.971519\n",
      "[1210]\ttrain-rmse:0.899191\tvalid-rmse:0.971509\n",
      "[1220]\ttrain-rmse:0.898782\tvalid-rmse:0.971493\n",
      "[1230]\ttrain-rmse:0.898415\tvalid-rmse:0.971489\n",
      "[1240]\ttrain-rmse:0.898079\tvalid-rmse:0.971469\n",
      "[1250]\ttrain-rmse:0.897735\tvalid-rmse:0.971462\n",
      "[1260]\ttrain-rmse:0.897251\tvalid-rmse:0.971457\n",
      "[1270]\ttrain-rmse:0.896885\tvalid-rmse:0.971449\n",
      "[1280]\ttrain-rmse:0.896464\tvalid-rmse:0.971434\n",
      "[1290]\ttrain-rmse:0.896056\tvalid-rmse:0.971436\n",
      "[1300]\ttrain-rmse:0.895707\tvalid-rmse:0.971418\n",
      "[1310]\ttrain-rmse:0.895225\tvalid-rmse:0.971402\n",
      "[1320]\ttrain-rmse:0.89486\tvalid-rmse:0.971393\n",
      "[1330]\ttrain-rmse:0.894443\tvalid-rmse:0.97138\n",
      "[1340]\ttrain-rmse:0.894076\tvalid-rmse:0.971362\n",
      "[1350]\ttrain-rmse:0.893641\tvalid-rmse:0.971354\n",
      "[1360]\ttrain-rmse:0.893334\tvalid-rmse:0.971341\n",
      "[1370]\ttrain-rmse:0.892903\tvalid-rmse:0.971327\n",
      "[1380]\ttrain-rmse:0.892518\tvalid-rmse:0.971309\n",
      "[1390]\ttrain-rmse:0.892159\tvalid-rmse:0.971312\n",
      "[1400]\ttrain-rmse:0.891784\tvalid-rmse:0.971309\n",
      "[1410]\ttrain-rmse:0.891406\tvalid-rmse:0.971298\n",
      "[1420]\ttrain-rmse:0.89101\tvalid-rmse:0.971296\n",
      "[1430]\ttrain-rmse:0.890717\tvalid-rmse:0.971294\n",
      "[1440]\ttrain-rmse:0.890303\tvalid-rmse:0.971279\n",
      "[1450]\ttrain-rmse:0.889876\tvalid-rmse:0.971274\n",
      "[1460]\ttrain-rmse:0.889518\tvalid-rmse:0.971262\n",
      "[1470]\ttrain-rmse:0.889148\tvalid-rmse:0.971254\n",
      "[1480]\ttrain-rmse:0.88874\tvalid-rmse:0.97125\n",
      "[1490]\ttrain-rmse:0.888316\tvalid-rmse:0.971248\n",
      "[1500]\ttrain-rmse:0.887896\tvalid-rmse:0.971239\n",
      "[1510]\ttrain-rmse:0.887546\tvalid-rmse:0.971233\n",
      "[1520]\ttrain-rmse:0.887156\tvalid-rmse:0.971221\n",
      "[1530]\ttrain-rmse:0.886811\tvalid-rmse:0.971211\n",
      "[1540]\ttrain-rmse:0.886352\tvalid-rmse:0.971222\n",
      "[1550]\ttrain-rmse:0.88597\tvalid-rmse:0.971217\n",
      "[1560]\ttrain-rmse:0.885644\tvalid-rmse:0.971221\n",
      "[1570]\ttrain-rmse:0.885266\tvalid-rmse:0.971216\n",
      "[1580]\ttrain-rmse:0.884916\tvalid-rmse:0.971212\n",
      "[1590]\ttrain-rmse:0.884446\tvalid-rmse:0.971198\n",
      "[1600]\ttrain-rmse:0.884101\tvalid-rmse:0.971184\n",
      "[1610]\ttrain-rmse:0.883771\tvalid-rmse:0.971181\n",
      "[1620]\ttrain-rmse:0.883363\tvalid-rmse:0.971168\n",
      "[1630]\ttrain-rmse:0.883054\tvalid-rmse:0.971161\n",
      "[1640]\ttrain-rmse:0.882672\tvalid-rmse:0.97115\n",
      "[1650]\ttrain-rmse:0.882277\tvalid-rmse:0.971143\n",
      "[1660]\ttrain-rmse:0.881856\tvalid-rmse:0.971137\n",
      "[1670]\ttrain-rmse:0.881423\tvalid-rmse:0.971125\n",
      "[1680]\ttrain-rmse:0.881129\tvalid-rmse:0.971125\n",
      "[1690]\ttrain-rmse:0.880763\tvalid-rmse:0.971131\n",
      "[1700]\ttrain-rmse:0.880329\tvalid-rmse:0.971129\n",
      "[1710]\ttrain-rmse:0.880018\tvalid-rmse:0.97112\n",
      "[1720]\ttrain-rmse:0.879679\tvalid-rmse:0.971119\n",
      "[1730]\ttrain-rmse:0.879273\tvalid-rmse:0.971118\n",
      "[1740]\ttrain-rmse:0.878917\tvalid-rmse:0.971113\n",
      "[1750]\ttrain-rmse:0.878527\tvalid-rmse:0.971111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1760]\ttrain-rmse:0.878147\tvalid-rmse:0.971097\n",
      "[1770]\ttrain-rmse:0.877859\tvalid-rmse:0.971103\n",
      "[1780]\ttrain-rmse:0.877394\tvalid-rmse:0.971099\n",
      "[1790]\ttrain-rmse:0.877017\tvalid-rmse:0.971102\n",
      "[1800]\ttrain-rmse:0.876556\tvalid-rmse:0.971107\n",
      "[1810]\ttrain-rmse:0.876149\tvalid-rmse:0.971108\n",
      "Stopping. Best iteration:\n",
      "[1760]\ttrain-rmse:0.878147\tvalid-rmse:0.971097\n",
      "\n",
      "Best RMSE at iteration: 1760\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix for training\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n",
    "# Create DMatrix for validation\n",
    "dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "# Define parameters\n",
    "# params = {\n",
    "#     'objective': 'reg:linear',\n",
    "#     'eval_metric': 'rmse',\n",
    "#     'alpha': 0.3, \n",
    "#     'colsample_bytree': 0.5,         \n",
    "#     'learning_rate': 0.02, \n",
    "#     'lambda': 10,\n",
    "#     'max_depth': 8, \n",
    "#     #'max_bin': 500,\n",
    "#     'min_child_weight': 150,\n",
    "#     'subsample': 0.8        \n",
    "    \n",
    "# }\n",
    "\n",
    "# Parameters from BO\n",
    "params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'alpha': 2.5315767101140376, \n",
    "    'colsample_bytree': 0.7870537878025798, \n",
    "    'learning_rate': 0.010692770887950544, \n",
    "    'lambda': 19.713199469203857, \n",
    "    'max_depth': 11, \n",
    "    'min_child_weight': 261, \n",
    "    'subsample': 0.835210157107768\n",
    "}\n",
    "\n",
    "# Train model\n",
    "num_rounds = 5000\n",
    "bst = xgb.train(params, dtrain, num_rounds, evals=evals, early_stopping_rounds=50, verbose_eval=10)\n",
    "print(\"Best RMSE at iteration:\", bst.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79d2b908",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: average_stars, Importance: 6793\n",
      "Feature: stars_y, Importance: 3266\n",
      "Feature: review_count_x, Importance: 2131\n",
      "Feature: user_eb87, Importance: 2073\n",
      "Feature: user_eb93, Importance: 2043\n",
      "Feature: user_eb81, Importance: 1974\n",
      "Feature: user_eb51, Importance: 1957\n",
      "Feature: user_eb85, Importance: 1935\n",
      "Feature: user_eb48, Importance: 1934\n",
      "Feature: user_eb77, Importance: 1887\n",
      "Feature: user_eb37, Importance: 1884\n",
      "Feature: user_eb54, Importance: 1857\n",
      "Feature: user_eb9, Importance: 1854\n",
      "Feature: user_eb1, Importance: 1833\n",
      "Feature: user_eb88, Importance: 1807\n",
      "Feature: user_eb40, Importance: 1806\n",
      "Feature: user_eb22, Importance: 1786\n",
      "Feature: user_eb34, Importance: 1767\n",
      "Feature: user_eb10, Importance: 1765\n",
      "Feature: user_eb46, Importance: 1757\n",
      "Feature: user_eb17, Importance: 1751\n",
      "Feature: user_eb100, Importance: 1751\n",
      "Feature: user_eb26, Importance: 1747\n",
      "Feature: user_eb31, Importance: 1739\n",
      "Feature: user_eb90, Importance: 1737\n",
      "Feature: review_count_y, Importance: 1727\n",
      "Feature: user_eb91, Importance: 1722\n",
      "Feature: user_eb66, Importance: 1718\n",
      "Feature: user_eb71, Importance: 1715\n",
      "Feature: user_eb43, Importance: 1712\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance = bst.get_score(importance_type='weight')\n",
    "\n",
    "# Sort features by importance\n",
    "sorted_importance = sorted(importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Display the top 30 features\n",
    "for feature, score in sorted_importance[:30]:\n",
    "    print(f\"Feature: {feature}, Importance: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69eebbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './models/model-ubcctEmbedding426-epoch100-RMSE971097.json'\n",
    "model_best_iter_file = './models/model-ubcctEmbedding426-epoch100-RMSE971097-best-iteration.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2676b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model_name = './models/model-ubcctEmbedding426-epoch100-RMSE97189.json'\n",
    "bst.save_model(model_name)\n",
    "\n",
    "#model_best_iter_file = './models/model-ubcctEmbedding426-epoch100-RMSE97189-best-iteration.txt'\n",
    "# Save the best iteration number to a file\n",
    "with open(model_best_iter_file, 'w') as f:\n",
    "    f.write(str(bst.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a57f987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9710966348648071\n"
     ]
    }
   ],
   "source": [
    "model_xgb = xgb.Booster()\n",
    "model_xgb.load_model(model_name)\n",
    "\n",
    "# Load the best iteration number\n",
    "with open(model_best_iter_file, 'r') as f:\n",
    "    best_iteration = int(f.read())\n",
    "    \n",
    "# Assuming you have a DMatrix for your evaluation set named \"dval\"\n",
    "y_pred = model_xgb.predict(dvalid, ntree_limit=best_iteration+1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(dvalid.get_label(), y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ac2d3",
   "metadata": {},
   "source": [
    "# Train full dataset combining training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a5f07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_data = pd.concat([train_data, val_data])\n",
    "X_full_train = full_train_data.drop('stars_x', axis=1)  \n",
    "y_full_train = full_train_data['stars_x'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd43b489",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_full = xgb.DMatrix(X_full_train, label=y_full_train)\n",
    "\n",
    "# Create DMatrix for validation\n",
    "dvalid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1be6f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:3.40671\tvalid-rmse:3.40506\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[10]\ttrain-rmse:3.09203\tvalid-rmse:3.09029\n",
      "[20]\ttrain-rmse:2.81319\tvalid-rmse:2.81135\n",
      "[30]\ttrain-rmse:2.56441\tvalid-rmse:2.5625\n",
      "[40]\ttrain-rmse:2.34492\tvalid-rmse:2.34294\n",
      "[50]\ttrain-rmse:2.15099\tvalid-rmse:2.14894\n",
      "[60]\ttrain-rmse:1.98083\tvalid-rmse:1.97871\n",
      "[70]\ttrain-rmse:1.83185\tvalid-rmse:1.82968\n",
      "[80]\ttrain-rmse:1.70206\tvalid-rmse:1.69982\n",
      "[90]\ttrain-rmse:1.58924\tvalid-rmse:1.58695\n",
      "[100]\ttrain-rmse:1.49235\tvalid-rmse:1.49002\n",
      "[110]\ttrain-rmse:1.40855\tvalid-rmse:1.40619\n",
      "[120]\ttrain-rmse:1.33682\tvalid-rmse:1.33447\n",
      "[130]\ttrain-rmse:1.27601\tvalid-rmse:1.27364\n",
      "[140]\ttrain-rmse:1.2245\tvalid-rmse:1.22214\n",
      "[150]\ttrain-rmse:1.18084\tvalid-rmse:1.17848\n",
      "[160]\ttrain-rmse:1.14399\tvalid-rmse:1.14164\n",
      "[170]\ttrain-rmse:1.11292\tvalid-rmse:1.11058\n",
      "[180]\ttrain-rmse:1.08691\tvalid-rmse:1.0846\n",
      "[190]\ttrain-rmse:1.06523\tvalid-rmse:1.06294\n",
      "[200]\ttrain-rmse:1.04694\tvalid-rmse:1.04469\n",
      "[210]\ttrain-rmse:1.03171\tvalid-rmse:1.0295\n",
      "[220]\ttrain-rmse:1.01894\tvalid-rmse:1.01675\n",
      "[230]\ttrain-rmse:1.00829\tvalid-rmse:1.00614\n",
      "[240]\ttrain-rmse:0.999341\tvalid-rmse:0.997228\n",
      "[250]\ttrain-rmse:0.991854\tvalid-rmse:0.989769\n",
      "[260]\ttrain-rmse:0.98543\tvalid-rmse:0.983356\n",
      "[270]\ttrain-rmse:0.980071\tvalid-rmse:0.978028\n",
      "[280]\ttrain-rmse:0.975447\tvalid-rmse:0.973424\n",
      "[290]\ttrain-rmse:0.971465\tvalid-rmse:0.969468\n",
      "[300]\ttrain-rmse:0.968014\tvalid-rmse:0.966033\n",
      "[310]\ttrain-rmse:0.965009\tvalid-rmse:0.963044\n",
      "[320]\ttrain-rmse:0.962374\tvalid-rmse:0.960417\n",
      "[330]\ttrain-rmse:0.960073\tvalid-rmse:0.958135\n",
      "[340]\ttrain-rmse:0.958034\tvalid-rmse:0.956112\n",
      "[350]\ttrain-rmse:0.956203\tvalid-rmse:0.954306\n",
      "[360]\ttrain-rmse:0.954521\tvalid-rmse:0.952627\n",
      "[370]\ttrain-rmse:0.953031\tvalid-rmse:0.951149\n",
      "[380]\ttrain-rmse:0.951619\tvalid-rmse:0.949734\n",
      "[390]\ttrain-rmse:0.950301\tvalid-rmse:0.948437\n",
      "[400]\ttrain-rmse:0.949107\tvalid-rmse:0.947249\n",
      "[410]\ttrain-rmse:0.947954\tvalid-rmse:0.946094\n",
      "[420]\ttrain-rmse:0.946867\tvalid-rmse:0.945017\n",
      "[430]\ttrain-rmse:0.945819\tvalid-rmse:0.943983\n",
      "[440]\ttrain-rmse:0.944874\tvalid-rmse:0.943053\n",
      "[450]\ttrain-rmse:0.943902\tvalid-rmse:0.942088\n",
      "[460]\ttrain-rmse:0.942975\tvalid-rmse:0.941153\n",
      "[470]\ttrain-rmse:0.942157\tvalid-rmse:0.940341\n",
      "[480]\ttrain-rmse:0.941345\tvalid-rmse:0.939525\n",
      "[490]\ttrain-rmse:0.940554\tvalid-rmse:0.938739\n",
      "[500]\ttrain-rmse:0.939785\tvalid-rmse:0.937985\n",
      "[510]\ttrain-rmse:0.939016\tvalid-rmse:0.937232\n",
      "[520]\ttrain-rmse:0.9382\tvalid-rmse:0.93641\n",
      "[530]\ttrain-rmse:0.937465\tvalid-rmse:0.935671\n",
      "[540]\ttrain-rmse:0.936819\tvalid-rmse:0.93503\n",
      "[550]\ttrain-rmse:0.936134\tvalid-rmse:0.934352\n",
      "[560]\ttrain-rmse:0.935451\tvalid-rmse:0.933678\n",
      "[570]\ttrain-rmse:0.934789\tvalid-rmse:0.933009\n",
      "[580]\ttrain-rmse:0.934155\tvalid-rmse:0.932382\n",
      "[590]\ttrain-rmse:0.933586\tvalid-rmse:0.931814\n",
      "[600]\ttrain-rmse:0.933007\tvalid-rmse:0.931232\n",
      "[610]\ttrain-rmse:0.932458\tvalid-rmse:0.930697\n",
      "[620]\ttrain-rmse:0.9319\tvalid-rmse:0.930133\n",
      "[630]\ttrain-rmse:0.931347\tvalid-rmse:0.929572\n",
      "[640]\ttrain-rmse:0.930833\tvalid-rmse:0.92907\n",
      "[650]\ttrain-rmse:0.930262\tvalid-rmse:0.928508\n",
      "[660]\ttrain-rmse:0.929675\tvalid-rmse:0.927927\n",
      "[670]\ttrain-rmse:0.929085\tvalid-rmse:0.927334\n",
      "[680]\ttrain-rmse:0.928478\tvalid-rmse:0.926732\n",
      "[690]\ttrain-rmse:0.927893\tvalid-rmse:0.926154\n",
      "[700]\ttrain-rmse:0.927407\tvalid-rmse:0.92568\n",
      "[710]\ttrain-rmse:0.926837\tvalid-rmse:0.925118\n",
      "[720]\ttrain-rmse:0.92629\tvalid-rmse:0.92457\n",
      "[730]\ttrain-rmse:0.925792\tvalid-rmse:0.924076\n",
      "[740]\ttrain-rmse:0.925256\tvalid-rmse:0.923541\n",
      "[750]\ttrain-rmse:0.924695\tvalid-rmse:0.922988\n",
      "[760]\ttrain-rmse:0.924253\tvalid-rmse:0.922539\n",
      "[770]\ttrain-rmse:0.923693\tvalid-rmse:0.921981\n",
      "[780]\ttrain-rmse:0.923236\tvalid-rmse:0.92153\n",
      "[790]\ttrain-rmse:0.922846\tvalid-rmse:0.92115\n",
      "[800]\ttrain-rmse:0.922382\tvalid-rmse:0.920687\n",
      "[810]\ttrain-rmse:0.921875\tvalid-rmse:0.920177\n",
      "[820]\ttrain-rmse:0.921437\tvalid-rmse:0.919741\n",
      "[830]\ttrain-rmse:0.920964\tvalid-rmse:0.919274\n",
      "[840]\ttrain-rmse:0.920446\tvalid-rmse:0.91875\n",
      "[850]\ttrain-rmse:0.919906\tvalid-rmse:0.918212\n",
      "[860]\ttrain-rmse:0.919477\tvalid-rmse:0.917786\n",
      "[870]\ttrain-rmse:0.918919\tvalid-rmse:0.917224\n",
      "[880]\ttrain-rmse:0.918528\tvalid-rmse:0.91684\n",
      "[890]\ttrain-rmse:0.918143\tvalid-rmse:0.916457\n",
      "[900]\ttrain-rmse:0.917718\tvalid-rmse:0.916037\n",
      "[910]\ttrain-rmse:0.917317\tvalid-rmse:0.91564\n",
      "[920]\ttrain-rmse:0.916921\tvalid-rmse:0.91525\n",
      "[930]\ttrain-rmse:0.916486\tvalid-rmse:0.91482\n",
      "[940]\ttrain-rmse:0.916101\tvalid-rmse:0.914439\n",
      "[950]\ttrain-rmse:0.915661\tvalid-rmse:0.914001\n",
      "[960]\ttrain-rmse:0.915328\tvalid-rmse:0.913672\n",
      "[970]\ttrain-rmse:0.914979\tvalid-rmse:0.91333\n",
      "[980]\ttrain-rmse:0.914674\tvalid-rmse:0.913024\n",
      "[990]\ttrain-rmse:0.914274\tvalid-rmse:0.91263\n",
      "[1000]\ttrain-rmse:0.913809\tvalid-rmse:0.912177\n",
      "[1010]\ttrain-rmse:0.913449\tvalid-rmse:0.911835\n",
      "[1020]\ttrain-rmse:0.913065\tvalid-rmse:0.91145\n",
      "[1030]\ttrain-rmse:0.912661\tvalid-rmse:0.91104\n",
      "[1040]\ttrain-rmse:0.912342\tvalid-rmse:0.910721\n",
      "[1050]\ttrain-rmse:0.911901\tvalid-rmse:0.910273\n",
      "[1060]\ttrain-rmse:0.911586\tvalid-rmse:0.909963\n",
      "[1070]\ttrain-rmse:0.911128\tvalid-rmse:0.909501\n",
      "[1080]\ttrain-rmse:0.910795\tvalid-rmse:0.909167\n",
      "[1090]\ttrain-rmse:0.910461\tvalid-rmse:0.908834\n",
      "[1100]\ttrain-rmse:0.910061\tvalid-rmse:0.90844\n",
      "[1110]\ttrain-rmse:0.909768\tvalid-rmse:0.908151\n",
      "[1120]\ttrain-rmse:0.909319\tvalid-rmse:0.907712\n",
      "[1130]\ttrain-rmse:0.908967\tvalid-rmse:0.907365\n",
      "[1140]\ttrain-rmse:0.908589\tvalid-rmse:0.906995\n",
      "[1150]\ttrain-rmse:0.908269\tvalid-rmse:0.906674\n",
      "[1160]\ttrain-rmse:0.907953\tvalid-rmse:0.906355\n",
      "[1170]\ttrain-rmse:0.907584\tvalid-rmse:0.905977\n",
      "[1180]\ttrain-rmse:0.907216\tvalid-rmse:0.905614\n",
      "[1190]\ttrain-rmse:0.906769\tvalid-rmse:0.905166\n",
      "[1200]\ttrain-rmse:0.906352\tvalid-rmse:0.904747\n",
      "[1210]\ttrain-rmse:0.906009\tvalid-rmse:0.904402\n",
      "[1220]\ttrain-rmse:0.905667\tvalid-rmse:0.904061\n",
      "[1230]\ttrain-rmse:0.905296\tvalid-rmse:0.903689\n",
      "[1240]\ttrain-rmse:0.904828\tvalid-rmse:0.903219\n",
      "[1250]\ttrain-rmse:0.904418\tvalid-rmse:0.902803\n",
      "[1260]\ttrain-rmse:0.904062\tvalid-rmse:0.902441\n",
      "[1270]\ttrain-rmse:0.903674\tvalid-rmse:0.902049\n",
      "[1280]\ttrain-rmse:0.903309\tvalid-rmse:0.901687\n",
      "[1290]\ttrain-rmse:0.902995\tvalid-rmse:0.901373\n",
      "[1300]\ttrain-rmse:0.902607\tvalid-rmse:0.900976\n",
      "[1310]\ttrain-rmse:0.902311\tvalid-rmse:0.900681\n",
      "[1320]\ttrain-rmse:0.901898\tvalid-rmse:0.900269\n",
      "[1330]\ttrain-rmse:0.901545\tvalid-rmse:0.899914\n",
      "[1340]\ttrain-rmse:0.901227\tvalid-rmse:0.899602\n",
      "[1350]\ttrain-rmse:0.900798\tvalid-rmse:0.899179\n",
      "[1360]\ttrain-rmse:0.900493\tvalid-rmse:0.898873\n",
      "[1370]\ttrain-rmse:0.900261\tvalid-rmse:0.898638\n",
      "[1380]\ttrain-rmse:0.899876\tvalid-rmse:0.898247\n",
      "[1390]\ttrain-rmse:0.899602\tvalid-rmse:0.897981\n",
      "[1400]\ttrain-rmse:0.899349\tvalid-rmse:0.897727\n",
      "[1410]\ttrain-rmse:0.899118\tvalid-rmse:0.897505\n",
      "[1420]\ttrain-rmse:0.898789\tvalid-rmse:0.897177\n",
      "[1430]\ttrain-rmse:0.898532\tvalid-rmse:0.896922\n",
      "[1440]\ttrain-rmse:0.898153\tvalid-rmse:0.896543\n",
      "[1450]\ttrain-rmse:0.897792\tvalid-rmse:0.896183\n",
      "[1460]\ttrain-rmse:0.897419\tvalid-rmse:0.895802\n",
      "[1470]\ttrain-rmse:0.897103\tvalid-rmse:0.895486\n",
      "[1480]\ttrain-rmse:0.896732\tvalid-rmse:0.895111\n",
      "[1490]\ttrain-rmse:0.896385\tvalid-rmse:0.894771\n",
      "[1500]\ttrain-rmse:0.896068\tvalid-rmse:0.894456\n",
      "[1510]\ttrain-rmse:0.895635\tvalid-rmse:0.894027\n",
      "[1520]\ttrain-rmse:0.895269\tvalid-rmse:0.893656\n",
      "[1530]\ttrain-rmse:0.894941\tvalid-rmse:0.893334\n",
      "[1540]\ttrain-rmse:0.894634\tvalid-rmse:0.893026\n",
      "[1550]\ttrain-rmse:0.89433\tvalid-rmse:0.892717\n",
      "[1560]\ttrain-rmse:0.89397\tvalid-rmse:0.892357\n",
      "[1570]\ttrain-rmse:0.893593\tvalid-rmse:0.891978\n",
      "[1580]\ttrain-rmse:0.893274\tvalid-rmse:0.891661\n",
      "[1590]\ttrain-rmse:0.892919\tvalid-rmse:0.891302\n",
      "[1599]\ttrain-rmse:0.892594\tvalid-rmse:0.890982\n",
      "Best RMSE at iteration: 1760\n"
     ]
    }
   ],
   "source": [
    "evals = [(dtrain_full, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "# Parameters from BO\n",
    "params = {\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'alpha': 2.5315767101140376, \n",
    "    'colsample_bytree': 0.7870537878025798, \n",
    "    'learning_rate': 0.010692770887950544, \n",
    "    'lambda': 19.713199469203857, \n",
    "    'max_depth': 11, \n",
    "    'min_child_weight': 261, \n",
    "    'subsample': 0.835210157107768\n",
    "}\n",
    "\n",
    "# Train model\n",
    "num_rounds = 1600\n",
    "final_model = xgb.train(params, dtrain_full, num_rounds, evals=evals, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b07d9352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE at iteration: 1599\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE at iteration:\", final_model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "22341ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './models/model-TrainVal-ubcctEmbedding426-epoch100-RMSE890982.json'\n",
    "model_best_iter_file = './models/model-TrainVal-ubcctEmbedding426-epoch100-RMSE890982-best-iteration.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "841afbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#model_name = './models/model-ubcctEmbedding426-epoch100-RMSE97189.json'\n",
    "final_model.save_model(model_name)\n",
    "\n",
    "#model_best_iter_file = './models/model-ubcctEmbedding426-epoch100-RMSE97189-best-iteration.txt'\n",
    "# Save the best iteration number to a file\n",
    "with open(model_best_iter_file, 'w') as f:\n",
    "    f.write(str(final_model.best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34575fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8909814953804016\n"
     ]
    }
   ],
   "source": [
    "final_model_xgb = xgb.Booster()\n",
    "final_model_xgb.load_model(model_name)\n",
    "\n",
    "# Load the best iteration number\n",
    "with open(model_best_iter_file, 'r') as f:\n",
    "    best_iteration = int(f.read())\n",
    "    \n",
    "# Assuming you have a DMatrix for your evaluation set named \"dval\"\n",
    "y_pred = final_model_xgb.predict(dvalid, ntree_limit=best_iteration+1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(dvalid.get_label(), y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad664bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">=0 and <1: 108400\n",
      ">=1 and <2: 28780\n",
      ">=2 and <3: 4532\n",
      ">=3 and <4: 332\n",
      ">=4: 0\n"
     ]
    }
   ],
   "source": [
    "# Print Error Distribution\n",
    "y_true = dvalid.get_label()\n",
    "\n",
    "# Calculate absolute errors\n",
    "abs_errors = np.abs(y_true - y_pred)\n",
    "\n",
    "# Define the error distribution bins\n",
    "error_bins = {'>=0 and <1': 0, '>=1 and <2': 0, '>=2 and <3': 0, '>=3 and <4': 0, '>=4': 0}\n",
    "\n",
    "# Increment the count in the appropriate bin\n",
    "for error in abs_errors:\n",
    "    if error >= 4:\n",
    "        error_bins['>=4'] += 1\n",
    "    elif error >= 3:\n",
    "        error_bins['>=3 and <4'] += 1\n",
    "    elif error >= 2:\n",
    "        error_bins['>=2 and <3'] += 1\n",
    "    elif error >= 1:\n",
    "        error_bins['>=1 and <2'] += 1\n",
    "    else:\n",
    "        error_bins['>=0 and <1'] += 1\n",
    "\n",
    "for r, count in error_bins.items():\n",
    "    print(f\"{r}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef08c6",
   "metadata": {},
   "source": [
    "# Hyperparameter tunning for XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a3d6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df6ddc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop('stars_x', axis=1) # Features\n",
    "y_train = train_data['stars_x'] # Target variable\n",
    "\n",
    "X_val = val_data.drop('stars_x', axis=1) # Features for evaluation data\n",
    "y_val = val_data['stars_x'] # True ratings for evaluation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a97a344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'rmse',\n",
    "        'alpha': trial.suggest_float('alpha', 0.1, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
    "        'lambda': trial.suggest_float('lambda', 1, 20),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 100, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1.0)\n",
    "    }\n",
    "\n",
    "    # Create DMatrix for training and validation\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "    # Train the model\n",
    "    num_rounds = 5000\n",
    "    model = xgb.train(params, dtrain, num_rounds, evals=evals, early_stopping_rounds=50, verbose_eval=0)\n",
    "\n",
    "    # Return the best validation RMSE\n",
    "    return model.best_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4d4dca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 07:57:08,661]\u001b[0m A new study created in memory with name: no-name-1b7340b0-e618-4198-9ec9-37047185dd0a\u001b[0m\n",
      "\u001b[32m[I 2023-12-03 08:17:36,252]\u001b[0m Trial 0 finished with value: 0.973538 and parameters: {'alpha': 3.5599386311312755, 'colsample_bytree': 0.9222685842493455, 'learning_rate': 0.05368006944638404, 'lambda': 14.735756471394263, 'max_depth': 6, 'min_child_weight': 240, 'subsample': 0.7295622824961296}. Best is trial 0 with value: 0.973538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.973538 and parameters: {'alpha': 3.5599386311312755, 'colsample_bytree': 0.9222685842493455, 'learning_rate': 0.05368006944638404, 'lambda': 14.735756471394263, 'max_depth': 6, 'min_child_weight': 240, 'subsample': 0.7295622824961296}.\n",
      "Best value so far: 0.973538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 09:00:03,550]\u001b[0m Trial 1 finished with value: 0.973745 and parameters: {'alpha': 9.464305216724641, 'colsample_bytree': 0.6104765814759154, 'learning_rate': 0.017351959456478425, 'lambda': 6.1335577563297115, 'max_depth': 4, 'min_child_weight': 158, 'subsample': 0.6076496839947623}. Best is trial 0 with value: 0.973538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.973745 and parameters: {'alpha': 9.464305216724641, 'colsample_bytree': 0.6104765814759154, 'learning_rate': 0.017351959456478425, 'lambda': 6.1335577563297115, 'max_depth': 4, 'min_child_weight': 158, 'subsample': 0.6076496839947623}.\n",
      "Best value so far: 0.973538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 09:08:07,088]\u001b[0m Trial 2 finished with value: 0.975075 and parameters: {'alpha': 9.143797937632241, 'colsample_bytree': 0.9708763023419246, 'learning_rate': 0.08144904877210958, 'lambda': 7.889431754222032, 'max_depth': 10, 'min_child_weight': 218, 'subsample': 0.5778424410382944}. Best is trial 0 with value: 0.973538.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.975075 and parameters: {'alpha': 9.143797937632241, 'colsample_bytree': 0.9708763023419246, 'learning_rate': 0.08144904877210958, 'lambda': 7.889431754222032, 'max_depth': 10, 'min_child_weight': 218, 'subsample': 0.5778424410382944}.\n",
      "Best value so far: 0.973538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 09:43:11,505]\u001b[0m Trial 3 finished with value: 0.973144 and parameters: {'alpha': 8.278160655491014, 'colsample_bytree': 0.5050039009767537, 'learning_rate': 0.015182912643913478, 'lambda': 3.523530787935206, 'max_depth': 5, 'min_child_weight': 137, 'subsample': 0.43615517739829357}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.973144 and parameters: {'alpha': 8.278160655491014, 'colsample_bytree': 0.5050039009767537, 'learning_rate': 0.015182912643913478, 'lambda': 3.523530787935206, 'max_depth': 5, 'min_child_weight': 137, 'subsample': 0.43615517739829357}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 09:58:07,563]\u001b[0m Trial 4 finished with value: 0.974639 and parameters: {'alpha': 6.218886702219857, 'colsample_bytree': 0.7120395914176371, 'learning_rate': 0.09417436760456355, 'lambda': 17.706770765549617, 'max_depth': 3, 'min_child_weight': 287, 'subsample': 0.9113552829271676}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.974639 and parameters: {'alpha': 6.218886702219857, 'colsample_bytree': 0.7120395914176371, 'learning_rate': 0.09417436760456355, 'lambda': 17.706770765549617, 'max_depth': 3, 'min_child_weight': 287, 'subsample': 0.9113552829271676}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 10:11:58,272]\u001b[0m Trial 5 finished with value: 0.97546 and parameters: {'alpha': 6.954379320375452, 'colsample_bytree': 0.6296843474569804, 'learning_rate': 0.06337624474238872, 'lambda': 9.243489295766238, 'max_depth': 3, 'min_child_weight': 202, 'subsample': 0.41935646404933}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 finished with value: 0.97546 and parameters: {'alpha': 6.954379320375452, 'colsample_bytree': 0.6296843474569804, 'learning_rate': 0.06337624474238872, 'lambda': 9.243489295766238, 'max_depth': 3, 'min_child_weight': 202, 'subsample': 0.41935646404933}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 10:30:59,942]\u001b[0m Trial 6 finished with value: 0.974924 and parameters: {'alpha': 7.407320739684848, 'colsample_bytree': 0.7102581720008061, 'learning_rate': 0.042469104050549385, 'lambda': 17.956034322141655, 'max_depth': 3, 'min_child_weight': 214, 'subsample': 0.45661846274097406}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 finished with value: 0.974924 and parameters: {'alpha': 7.407320739684848, 'colsample_bytree': 0.7102581720008061, 'learning_rate': 0.042469104050549385, 'lambda': 17.956034322141655, 'max_depth': 3, 'min_child_weight': 214, 'subsample': 0.45661846274097406}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 10:45:27,833]\u001b[0m Trial 7 finished with value: 0.974472 and parameters: {'alpha': 4.82559075405013, 'colsample_bytree': 0.6440261880300254, 'learning_rate': 0.06760366276735703, 'lambda': 15.311519550962124, 'max_depth': 4, 'min_child_weight': 215, 'subsample': 0.6546429846544746}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 finished with value: 0.974472 and parameters: {'alpha': 4.82559075405013, 'colsample_bytree': 0.6440261880300254, 'learning_rate': 0.06760366276735703, 'lambda': 15.311519550962124, 'max_depth': 4, 'min_child_weight': 215, 'subsample': 0.6546429846544746}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 10:51:14,636]\u001b[0m Trial 8 finished with value: 0.975185 and parameters: {'alpha': 0.26080647826524117, 'colsample_bytree': 0.5854318333406645, 'learning_rate': 0.08751618426500075, 'lambda': 8.184545927801121, 'max_depth': 12, 'min_child_weight': 251, 'subsample': 0.7088035906856436}. Best is trial 3 with value: 0.973144.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8 finished with value: 0.975185 and parameters: {'alpha': 0.26080647826524117, 'colsample_bytree': 0.5854318333406645, 'learning_rate': 0.08751618426500075, 'lambda': 8.184545927801121, 'max_depth': 12, 'min_child_weight': 251, 'subsample': 0.7088035906856436}.\n",
      "Best value so far: 0.973144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 11:59:30,711]\u001b[0m Trial 9 finished with value: 0.971138 and parameters: {'alpha': 7.196324518026052, 'colsample_bytree': 0.6155127541727401, 'learning_rate': 0.010024275555949036, 'lambda': 15.605384373450232, 'max_depth': 10, 'min_child_weight': 274, 'subsample': 0.5322992890217315}. Best is trial 9 with value: 0.971138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 finished with value: 0.971138 and parameters: {'alpha': 7.196324518026052, 'colsample_bytree': 0.6155127541727401, 'learning_rate': 0.010024275555949036, 'lambda': 15.605384373450232, 'max_depth': 10, 'min_child_weight': 274, 'subsample': 0.5322992890217315}.\n",
      "Best value so far: 0.971138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 12:24:28,869]\u001b[0m Trial 10 finished with value: 0.972382 and parameters: {'alpha': 2.952806746664268, 'colsample_bytree': 0.8712708476139344, 'learning_rate': 0.034093556672554884, 'lambda': 13.374575695864536, 'max_depth': 9, 'min_child_weight': 299, 'subsample': 0.8950327128391171}. Best is trial 9 with value: 0.971138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 finished with value: 0.972382 and parameters: {'alpha': 2.952806746664268, 'colsample_bytree': 0.8712708476139344, 'learning_rate': 0.034093556672554884, 'lambda': 13.374575695864536, 'max_depth': 9, 'min_child_weight': 299, 'subsample': 0.8950327128391171}.\n",
      "Best value so far: 0.971138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 12:55:25,099]\u001b[0m Trial 11 finished with value: 0.972079 and parameters: {'alpha': 2.607294932117917, 'colsample_bytree': 0.8475854755153138, 'learning_rate': 0.0315314029856972, 'lambda': 12.457215533644675, 'max_depth': 9, 'min_child_weight': 293, 'subsample': 0.9894619780562619}. Best is trial 9 with value: 0.971138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11 finished with value: 0.972079 and parameters: {'alpha': 2.607294932117917, 'colsample_bytree': 0.8475854755153138, 'learning_rate': 0.0315314029856972, 'lambda': 12.457215533644675, 'max_depth': 9, 'min_child_weight': 293, 'subsample': 0.9894619780562619}.\n",
      "Best value so far: 0.971138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 13:28:28,304]\u001b[0m Trial 12 finished with value: 0.972627 and parameters: {'alpha': 1.166376915050888, 'colsample_bytree': 0.8062624185355353, 'learning_rate': 0.029151698953757244, 'lambda': 12.075330965839495, 'max_depth': 8, 'min_child_weight': 270, 'subsample': 0.9921380938076089}. Best is trial 9 with value: 0.971138.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12 finished with value: 0.972627 and parameters: {'alpha': 1.166376915050888, 'colsample_bytree': 0.8062624185355353, 'learning_rate': 0.029151698953757244, 'lambda': 12.075330965839495, 'max_depth': 8, 'min_child_weight': 270, 'subsample': 0.9921380938076089}.\n",
      "Best value so far: 0.971138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-03 14:46:50,863]\u001b[0m Trial 13 finished with value: 0.971097 and parameters: {'alpha': 2.5315767101140376, 'colsample_bytree': 0.7870537878025798, 'learning_rate': 0.010692770887950544, 'lambda': 19.713199469203857, 'max_depth': 11, 'min_child_weight': 261, 'subsample': 0.835210157107768}. Best is trial 13 with value: 0.971097.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13 finished with value: 0.971097 and parameters: {'alpha': 2.5315767101140376, 'colsample_bytree': 0.7870537878025798, 'learning_rate': 0.010692770887950544, 'lambda': 19.713199469203857, 'max_depth': 11, 'min_child_weight': 261, 'subsample': 0.835210157107768}.\n",
      "Best value so far: 0.971097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-12-03 14:49:58,918]\u001b[0m Trial 14 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aoyanliang/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-35-f8e833e8e721>\", line 22, in objective\n",
      "    model = xgb.train(params, dtrain, num_rounds, evals=evals, early_stopping_rounds=50, verbose_eval=0)\n",
      "  File \"/Users/aoyanliang/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/training.py\", line 204, in train\n",
      "    xgb_model=xgb_model, callbacks=callbacks)\n",
      "  File \"/Users/aoyanliang/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/training.py\", line 74, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/aoyanliang/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/core.py\", line 894, in update\n",
      "    dtrain.handle))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-721e38caf39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustom_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-f8e833e8e721>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mnum_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Return the best validation RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 894\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def custom_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value} and parameters: {trial.params}.\")\n",
    "    print(f\"Best value so far: {study.best_value}\")\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100, callbacks=[custom_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7015d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
