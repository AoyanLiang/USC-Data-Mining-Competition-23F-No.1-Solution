{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02501cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d8c1a307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aoyanliang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aoyanliang/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you haven't downloaded stopwords from nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a68d8",
   "metadata": {},
   "source": [
    "# <font color='red'>FEATURE PROCESSING</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "477c08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the JSON data into a DataFrame\n",
    "user_df = pd.read_json('data/user.json', lines=True)\n",
    "business_df = pd.read_json('data/business.json', lines=True)\n",
    "review_df = pd.read_json('data/review_train.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3246bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df['user_id'] = user_df['user_id'].astype(str) + '-u'\n",
    "business_df['business_id'] = business_df['business_id'].astype(str) + '-b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112f5a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1518169 entries, 0 to 1518168\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count    Dtype  \n",
      "---  ------              --------------    -----  \n",
      " 0   user_id             1518169 non-null  object \n",
      " 1   name                1518169 non-null  object \n",
      " 2   review_count        1518169 non-null  int64  \n",
      " 3   yelping_since       1518169 non-null  object \n",
      " 4   friends             1518169 non-null  object \n",
      " 5   useful              1518169 non-null  int64  \n",
      " 6   funny               1518169 non-null  int64  \n",
      " 7   cool                1518169 non-null  int64  \n",
      " 8   fans                1518169 non-null  int64  \n",
      " 9   elite               1518169 non-null  object \n",
      " 10  average_stars       1518169 non-null  float64\n",
      " 11  compliment_hot      1518169 non-null  int64  \n",
      " 12  compliment_more     1518169 non-null  int64  \n",
      " 13  compliment_profile  1518169 non-null  int64  \n",
      " 14  compliment_cute     1518169 non-null  int64  \n",
      " 15  compliment_list     1518169 non-null  int64  \n",
      " 16  compliment_note     1518169 non-null  int64  \n",
      " 17  compliment_plain    1518169 non-null  int64  \n",
      " 18  compliment_cool     1518169 non-null  int64  \n",
      " 19  compliment_funny    1518169 non-null  int64  \n",
      " 20  compliment_writer   1518169 non-null  int64  \n",
      " 21  compliment_photos   1518169 non-null  int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 254.8+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188593 entries, 0 to 188592\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   business_id   188593 non-null  object \n",
      " 1   name          188593 non-null  object \n",
      " 2   neighborhood  188593 non-null  object \n",
      " 3   address       188593 non-null  object \n",
      " 4   city          188593 non-null  object \n",
      " 5   state         188593 non-null  object \n",
      " 6   postal_code   188593 non-null  object \n",
      " 7   latitude      188587 non-null  float64\n",
      " 8   longitude     188587 non-null  float64\n",
      " 9   stars         188593 non-null  float64\n",
      " 10  review_count  188593 non-null  int64  \n",
      " 11  is_open       188593 non-null  int64  \n",
      " 12  attributes    162807 non-null  object \n",
      " 13  categories    188052 non-null  object \n",
      " 14  hours         143791 non-null  object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 21.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 455855 entries, 0 to 455854\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   review_id    455855 non-null  object        \n",
      " 1   user_id      455855 non-null  object        \n",
      " 2   business_id  455855 non-null  object        \n",
      " 3   stars        455855 non-null  int64         \n",
      " 4   date         455855 non-null  datetime64[ns]\n",
      " 5   text         455855 non-null  object        \n",
      " 6   useful       455855 non-null  int64         \n",
      " 7   funny        455855 non-null  int64         \n",
      " 8   cool         455855 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 31.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 2. Inspect the DataFrame\n",
    "print(user_df.info())\n",
    "print(business_df.info())\n",
    "print(review_df.info())\n",
    "# 3. Look at the first few rows\n",
    "# print(df.head())\n",
    "\n",
    "# 4. Statistical summary\n",
    "#print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73201586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388\n"
     ]
    }
   ],
   "source": [
    "# Normalize the city names by stripping leading/trailing spaces and converting to lowercase\n",
    "normalized_cities = business_df['neighborhood'].str.strip().str.lower().unique()\n",
    "\n",
    "# Now calculate the number of unique cities\n",
    "num_normalized_unique_cities = len(normalized_cities)\n",
    "\n",
    "print(num_normalized_unique_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d716947",
   "metadata": {},
   "source": [
    "## review text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "aeee1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove stopwords\n",
    "    text = word_tokenize(text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "review_df['cleaned_text'] = review_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "57398045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec Model\n",
    "\n",
    "# List of list of tokens is needed for Word2Vec training\n",
    "sentences = review_df['cleaned_text'].tolist()\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model_w2v = Word2Vec(sentences, size=10, window=5, min_count=1, workers=4)\n",
    "model_w2v.save(\"./models/word2vec-10.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "3b9e4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aoyanliang/anaconda3/envs/dsci553-spark-py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model_w2v = Word2Vec.load(\"./models/word2vec-10.model\")\n",
    "\n",
    "def get_vector(word_list, model):\n",
    "    # Retrieve vector for each word and take the mean\n",
    "    vector_list = [model_w2v.wv[word] for word in word_list if word in model_w2v.wv.vocab]\n",
    "    vector = np.mean(vector_list, axis=0)\n",
    "    return vector\n",
    "\n",
    "review_df['text_vector'] = review_df['cleaned_text'].apply(lambda x: get_vector(x, model_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "77655033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we're using mean for aggregation\n",
    "def vector_mean(vectors):\n",
    "    return np.mean(vectors, axis=0).tolist()\n",
    "\n",
    "user_review_aggregations = review_df.groupby('user_id').agg({\n",
    "    #'stars': 'mean',\n",
    "    #'useful': 'mean',\n",
    "    #'funny': 'mean',\n",
    "    #'cool': 'mean',\n",
    "    'text_vector': vector_mean\n",
    "}).reset_index()\n",
    "\n",
    "business_review_aggregations = review_df.groupby('business_id').agg({\n",
    "    #'stars': 'mean',\n",
    "    #'useful': 'mean',\n",
    "    #'funny': 'mean',\n",
    "    #'cool': 'mean',\n",
    "    'text_vector': vector_mean\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "d5410464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save these features\n",
    "user_review_aggregations.to_csv('./embeded_features/user_review_aggregations.csv', index=False)\n",
    "business_review_aggregations.to_csv('./embeded_features/business_review_aggregations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf0e30",
   "metadata": {},
   "source": [
    "## Graph embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d77d249",
   "metadata": {},
   "source": [
    "### Create User-User Edges DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4aa91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64886928 entries, 0 to 64886927\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   user_id    object\n",
      " 1   friend_id  object\n",
      "dtypes: object(2)\n",
      "memory usage: 990.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'None' is used when there are no friends listed\n",
    "user_df['friends'] = user_df['friends'].fillna('None')\n",
    "\n",
    "# Create user-user edges\n",
    "user_user_edges = (\n",
    "    user_df[user_df['friends'] != 'None']\n",
    "    .assign(friends=lambda df: df['friends'].str.split(', '))\n",
    "    .explode('friends')[['user_id', 'friends']]  # Select only the relevant columns\n",
    "    .dropna()  # Drop any rows that have NaN values after explode\n",
    "    .rename(columns={'user_id': 'user_id', 'friends': 'friend_id'})\n",
    "    .reset_index(drop=True)  # Reset the index, dropping the old one\n",
    ")\n",
    "\n",
    "# Append '-u' to each user ID\n",
    "user_user_edges['user_id'] = user_user_edges['user_id'].astype(str) + '-u'\n",
    "user_user_edges['friend_id'] = user_user_edges['friend_id'].astype(str) + '-u'\n",
    "\n",
    "# Now, user_user_edges contains only 'source' and 'target' columns\n",
    "\n",
    "user_user_edges.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7b9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge type column\n",
    "user_user_edges['edge_type'] = 'friendship'\n",
    "\n",
    "# Save to TSV\n",
    "user_user_edges.to_csv('graph_edges/user_user_edges_relation.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cd53b",
   "metadata": {},
   "source": [
    "### Create User-Business Edges DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f9e393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YHWsLBS8jzZiPjKHMFOaAA-u</td>\n",
       "      <td>iKMLsX1Je7P3wAOEc9scDg-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YHWsLBS8jzZiPjKHMFOaAA-u</td>\n",
       "      <td>qhJ4GDULYbdb_sctDgbZgw-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YHWsLBS8jzZiPjKHMFOaAA-u</td>\n",
       "      <td>gl1zQmiA8MUHmLL2wsCdVA-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YHWsLBS8jzZiPjKHMFOaAA-u</td>\n",
       "      <td>OR6iRk0vrMzE-1gLg-WYrw-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YHWsLBS8jzZiPjKHMFOaAA-u</td>\n",
       "      <td>HOGdBz2w9VZbw2yyM-WA3g-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455850</th>\n",
       "      <td>3LC2sKfvz_nWuJquUDsNnw-u</td>\n",
       "      <td>t67GMPZ0cv_ItKlID-JFiQ-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455851</th>\n",
       "      <td>3LC2sKfvz_nWuJquUDsNnw-u</td>\n",
       "      <td>wsmVIHJEi9J_38dXx2qLKA-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455852</th>\n",
       "      <td>3LC2sKfvz_nWuJquUDsNnw-u</td>\n",
       "      <td>j1i7s55PmOFzJC3l6O8PiA-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455853</th>\n",
       "      <td>3LC2sKfvz_nWuJquUDsNnw-u</td>\n",
       "      <td>zjwdU1OdlbKTGjm-IfD4TQ-b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455854</th>\n",
       "      <td>3LC2sKfvz_nWuJquUDsNnw-u</td>\n",
       "      <td>HHCn1akqIpl_BhdcJoYPbw-b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455855 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         user_id               business_id\n",
       "0       YHWsLBS8jzZiPjKHMFOaAA-u  iKMLsX1Je7P3wAOEc9scDg-b\n",
       "1       YHWsLBS8jzZiPjKHMFOaAA-u  qhJ4GDULYbdb_sctDgbZgw-b\n",
       "2       YHWsLBS8jzZiPjKHMFOaAA-u  gl1zQmiA8MUHmLL2wsCdVA-b\n",
       "3       YHWsLBS8jzZiPjKHMFOaAA-u  OR6iRk0vrMzE-1gLg-WYrw-b\n",
       "4       YHWsLBS8jzZiPjKHMFOaAA-u  HOGdBz2w9VZbw2yyM-WA3g-b\n",
       "...                          ...                       ...\n",
       "455850  3LC2sKfvz_nWuJquUDsNnw-u  t67GMPZ0cv_ItKlID-JFiQ-b\n",
       "455851  3LC2sKfvz_nWuJquUDsNnw-u  wsmVIHJEi9J_38dXx2qLKA-b\n",
       "455852  3LC2sKfvz_nWuJquUDsNnw-u  j1i7s55PmOFzJC3l6O8PiA-b\n",
       "455853  3LC2sKfvz_nWuJquUDsNnw-u  zjwdU1OdlbKTGjm-IfD4TQ-b\n",
       "455854  3LC2sKfvz_nWuJquUDsNnw-u  HHCn1akqIpl_BhdcJoYPbw-b\n",
       "\n",
       "[455855 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create user-business edges\n",
    "user_business_edges = review_df[['user_id', 'business_id']].copy()\n",
    "user_business_edges['user_id'] = user_business_edges['user_id'].astype(str) + '-u'\n",
    "user_business_edges['business_id'] = user_business_edges['business_id'].astype(str) + '-b'\n",
    "user_business_edges = user_business_edges.rename(columns={'user_id': 'user_id', 'business_id': 'business_id'})\n",
    "\n",
    "user_business_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b728da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge type column\n",
    "user_business_edges['edge_type'] = 'reviewed'\n",
    "\n",
    "# Save to TSV\n",
    "user_business_edges.to_csv('graph_edges/user_business_edges_relation_directed.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059f681",
   "metadata": {},
   "source": [
    "### Create Business-Category Edges DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4ee526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>Tours-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>Breweries-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>Pizza-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>Restaurants-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>Food-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739017</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>Shopping-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739018</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>Hair_Salons-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739019</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>Fashion-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739020</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>Hair_Stylists-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739021</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>Beauty_&amp;_Spas-c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>739022 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          source           target\n",
       "0       Apn5Q_b6Nz61Tq4XzPdf9A-b          Tours-c\n",
       "1       Apn5Q_b6Nz61Tq4XzPdf9A-b      Breweries-c\n",
       "2       Apn5Q_b6Nz61Tq4XzPdf9A-b          Pizza-c\n",
       "3       Apn5Q_b6Nz61Tq4XzPdf9A-b    Restaurants-c\n",
       "4       Apn5Q_b6Nz61Tq4XzPdf9A-b           Food-c\n",
       "...                          ...              ...\n",
       "739017  NkOvIueadjFUxeCyq_uQEw-b       Shopping-c\n",
       "739018  NkOvIueadjFUxeCyq_uQEw-b    Hair_Salons-c\n",
       "739019  NkOvIueadjFUxeCyq_uQEw-b        Fashion-c\n",
       "739020  NkOvIueadjFUxeCyq_uQEw-b  Hair_Stylists-c\n",
       "739021  NkOvIueadjFUxeCyq_uQEw-b  Beauty_&_Spas-c\n",
       "\n",
       "[739022 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create business-category edges\n",
    "business_category_edges = (\n",
    "    business_df.dropna(subset=['categories'])\n",
    "    .assign(categories=lambda df: df['categories'].str.split(', '))\n",
    "    .explode('categories')[['business_id', 'categories']]  # Select only the relevant columns\n",
    "    .dropna()  # Drop any rows that have NaN values after explode\n",
    "    .rename(columns={'business_id': 'source', 'categories': 'target'})\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "business_category_edges['source'] = business_category_edges['source'].astype(str) + '-b'\n",
    "business_category_edges['target'] = business_category_edges['target'].str.replace(' ', '_').astype(str) + '-c'\n",
    "\n",
    "business_category_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cec2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge type column\n",
    "business_category_edges['edge_type'] = 'belongs'\n",
    "\n",
    "# Save to TSV\n",
    "business_category_edges.to_csv('graph_edges/business_category_edges_relation_directed.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765f793",
   "metadata": {},
   "source": [
    "### Create Business-City Edges DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fb3183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A-b</td>\n",
       "      <td>calgary-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AjEbIBw6ZFfln7ePHha9PA-b</td>\n",
       "      <td>henderson-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O8S5hYJ1SMc8fA4QBtVujA-b</td>\n",
       "      <td>montréal-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bFzdJJ3wp3PZssNEsyU23g-b</td>\n",
       "      <td>phoenix-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8USyCYqpScwiNEb58Bt6CA-b</td>\n",
       "      <td>calgary-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188588</th>\n",
       "      <td>sMQAZ3DkfrURFoJAyOhjEw-b</td>\n",
       "      <td>pittsburgh-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188589</th>\n",
       "      <td>6hvuCibNS4uECetHb9MCQQ-b</td>\n",
       "      <td>pittsburgh-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188590</th>\n",
       "      <td>KleCXFYOmdACcQUvf6_XEg-b</td>\n",
       "      <td>concord-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188591</th>\n",
       "      <td>3_fIsSxN2RBovQ_6EFtLzA-b</td>\n",
       "      <td>concord-ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188592</th>\n",
       "      <td>NkOvIueadjFUxeCyq_uQEw-b</td>\n",
       "      <td>las_vegas-ct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188593 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     business_id           city\n",
       "0       Apn5Q_b6Nz61Tq4XzPdf9A-b     calgary-ct\n",
       "1       AjEbIBw6ZFfln7ePHha9PA-b   henderson-ct\n",
       "2       O8S5hYJ1SMc8fA4QBtVujA-b    montréal-ct\n",
       "3       bFzdJJ3wp3PZssNEsyU23g-b     phoenix-ct\n",
       "4       8USyCYqpScwiNEb58Bt6CA-b     calgary-ct\n",
       "...                          ...            ...\n",
       "188588  sMQAZ3DkfrURFoJAyOhjEw-b  pittsburgh-ct\n",
       "188589  6hvuCibNS4uECetHb9MCQQ-b  pittsburgh-ct\n",
       "188590  KleCXFYOmdACcQUvf6_XEg-b     concord-ct\n",
       "188591  3_fIsSxN2RBovQ_6EFtLzA-b     concord-ct\n",
       "188592  NkOvIueadjFUxeCyq_uQEw-b   las_vegas-ct\n",
       "\n",
       "[188593 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy relevant columns to create business-city edges DataFrame\n",
    "business_city_edges = business_df[['business_id', 'city']].copy()\n",
    "\n",
    "# Append suffixes to identifiers in the new DataFrame\n",
    "business_city_edges['business_id'] = business_city_edges['business_id'].astype(str) + '-b'\n",
    "business_city_edges['city'] = business_city_edges['city'].astype(str) + '-ct'\n",
    "\n",
    "# Perform the cleaning and filtering steps\n",
    "# Trim leading/trailing spaces and convert to lowercase for city\n",
    "business_city_edges['city'] = business_city_edges['city'].str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Filter out rows where the city is an empty string or only the suffix\n",
    "business_city_edges = business_city_edges[business_city_edges['city'] != '-cy']\n",
    "business_city_edges = business_city_edges.reset_index(drop=True)\n",
    "business_city_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7696a933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge type column\n",
    "business_city_edges['edge_type'] = 'in'\n",
    "\n",
    "# Save to TSV\n",
    "business_city_edges.to_csv('graph_edges/business_city_edges_relation_directed.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded46b13",
   "metadata": {},
   "source": [
    "### Separate embedding files from Pytorch-Biggraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d04afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100000 lines\n",
      "Processed 200000 lines\n",
      "Processed 300000 lines\n",
      "Processed 400000 lines\n",
      "Processed 500000 lines\n",
      "Processed 600000 lines\n",
      "Processed 700000 lines\n",
      "Processed 800000 lines\n",
      "Processed 900000 lines\n",
      "Processed 1000000 lines\n",
      "Processed 1100000 lines\n",
      "Processed 1200000 lines\n",
      "Processed 1300000 lines\n",
      "Processed 1400000 lines\n",
      "Processed 1500000 lines\n",
      "Processed 1600000 lines\n",
      "Processed 1700000 lines\n",
      "Processed 1800000 lines\n",
      "Processed 1900000 lines\n",
      "Processed 2000000 lines\n",
      "Processed 2100000 lines\n",
      "Processed 2200000 lines\n",
      "Processed 2300000 lines\n",
      "Processed 2400000 lines\n",
      "Processed 2500000 lines\n",
      "Processed 2600000 lines\n",
      "Processed 2700000 lines\n",
      "Processed 2800000 lines\n",
      "Processed 2900000 lines\n",
      "Processed 3000000 lines\n",
      "Processed 3100000 lines\n",
      "Processed 3200000 lines\n",
      "Processed 3300000 lines\n",
      "Processed 3400000 lines\n",
      "Processed 3500000 lines\n",
      "Processed 3600000 lines\n",
      "Processed 3700000 lines\n",
      "Processed 3800000 lines\n",
      "Processed 3900000 lines\n",
      "Processed 4000000 lines\n",
      "Processed 4100000 lines\n",
      "Processed 4200000 lines\n",
      "Processed 4300000 lines\n",
      "Processed 4400000 lines\n",
      "Processed 4500000 lines\n",
      "Processed 4600000 lines\n",
      "Processed 4700000 lines\n",
      "Processed 4800000 lines\n",
      "Processed 4900000 lines\n",
      "Processed 5000000 lines\n",
      "Processed 5100000 lines\n",
      "Processed 5200000 lines\n",
      "Processed 5300000 lines\n",
      "Processed 5400000 lines\n",
      "Processed 5500000 lines\n",
      "Processed 5600000 lines\n",
      "Processed 5700000 lines\n",
      "Processed 5800000 lines\n",
      "Processed 5900000 lines\n",
      "Processed 6000000 lines\n",
      "Processed 6100000 lines\n",
      "Processed 6200000 lines\n",
      "Processed 6300000 lines\n",
      "Processed 6400000 lines\n",
      "Processed 6500000 lines\n",
      "Processed 6600000 lines\n",
      "Processed 6700000 lines\n",
      "Processed 6800000 lines\n",
      "Processed 6900000 lines\n",
      "Processed 7000000 lines\n",
      "Processed 7100000 lines\n",
      "Processed 7200000 lines\n",
      "Processed 7300000 lines\n",
      "Processed 7400000 lines\n",
      "Processed 7500000 lines\n",
      "Processed 7600000 lines\n",
      "Processed 7700000 lines\n",
      "Processed 7800000 lines\n",
      "Processed 7900000 lines\n",
      "Processed 8000000 lines\n",
      "Processed 8100000 lines\n",
      "Processed 8200000 lines\n",
      "Processed 8300000 lines\n",
      "Processed 8400000 lines\n",
      "Processed 8500000 lines\n",
      "Processed 8600000 lines\n",
      "Processed 8700000 lines\n",
      "Processed 8800000 lines\n",
      "Processed 8900000 lines\n",
      "Processed 9000000 lines\n",
      "Processed 9100000 lines\n",
      "Processed 9200000 lines\n",
      "Processed 9300000 lines\n",
      "Processed 9400000 lines\n",
      "Processed 9500000 lines\n",
      "Processed 9600000 lines\n",
      "Processed 9700000 lines\n",
      "Processed 9800000 lines\n",
      "Processed 9900000 lines\n",
      "Processed 10000000 lines\n",
      "Processed 10100000 lines\n",
      "Processed 10200000 lines\n",
      "Processed 10300000 lines\n",
      "Processed 10400000 lines\n",
      "Processed 10500000 lines\n",
      "Processed 10600000 lines\n",
      "Processed 10700000 lines\n",
      "Processed 10800000 lines\n",
      "Processed 10900000 lines\n",
      "Processed 11000000 lines\n",
      "Processed 11100000 lines\n",
      "Processed 11200000 lines\n",
      "Processed 11300000 lines\n",
      "Processed 11400000 lines\n",
      "Processed 11500000 lines\n",
      "Processed 11600000 lines\n",
      "Processed 11700000 lines\n",
      "Processed 11800000 lines\n",
      "Processed 11900000 lines\n",
      "Processed 12000000 lines\n",
      "Processed 12100000 lines\n",
      "Processed 12200000 lines\n",
      "Processed 12300000 lines\n",
      "Processed 12400000 lines\n",
      "Processed 12500000 lines\n",
      "Processed 12600000 lines\n",
      "Processed 12700000 lines\n",
      "Processed 12800000 lines\n",
      "Processed 12900000 lines\n",
      "Processed 13000000 lines\n",
      "Processed 13100000 lines\n",
      "Total: 13179264 lines\n"
     ]
    }
   ],
   "source": [
    "# finished PBG embedding on CARC using 1 node with 64 core in ~30 mins for 10 epoch\n",
    "# 1 hour 30 mins for 100 epoch\n",
    "# 2 hour 30 mins for 200 epoch\n",
    "\n",
    "# Path to the large embedding file\n",
    "embedding_file_path = './embeded_features/PBG/epoch200/ubcct_embeddings-epoch200.tsv'\n",
    "\n",
    "# Paths to the output files for each node type\n",
    "output_files = {\n",
    "    'user': './embeded_features/PBG/epoch200/user_embeddings.tsv',\n",
    "    'business': './embeded_features/PBG/epoch200/business_embeddings.tsv',\n",
    "    'category': './embeded_features/PBG/epoch200/category_embeddings.tsv',\n",
    "    'city': './embeded_features/PBG/epoch200/city_embeddings.tsv'\n",
    "}\n",
    "\n",
    "# Function to separate the embeddings based on the node type suffixes\n",
    "def separate_embeddings(embedding_file, output_files):\n",
    "    # Open all output files in write mode\n",
    "    with open(output_files['user'], 'w') as user_file, \\\n",
    "         open(output_files['business'], 'w') as business_file, \\\n",
    "         open(output_files['category'], 'w') as category_file, \\\n",
    "         open(output_files['city'], 'w') as city_file:\n",
    "\n",
    "        # Open the large embedding file and process line by line\n",
    "        with open(embedding_file, 'r') as file:\n",
    "            line_count = 0\n",
    "            for line in file:\n",
    "                line_count += 1\n",
    "                node_id = line.split('\\t')[0]\n",
    "\n",
    "                # Determine the node type and write to the corresponding file\n",
    "                if node_id.endswith('-u'):\n",
    "                    user_file.write(line)\n",
    "                elif node_id.endswith('-b'):\n",
    "                    business_file.write(line)\n",
    "                elif node_id.endswith('-c'):\n",
    "                    category_file.write(line)\n",
    "                elif node_id.endswith('-ct'):\n",
    "                    city_file.write(line)\n",
    "                    \n",
    "                # Print progress every 100000 lines\n",
    "                if line_count % 100000 == 0:\n",
    "                    print(f\"Processed {line_count} lines\")\n",
    "            print(f\"Total: {line_count} lines\")\n",
    "\n",
    "# Run the function\n",
    "separate_embeddings(embedding_file_path, output_files)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
